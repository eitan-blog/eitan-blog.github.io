<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;example.com&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Muse&quot;,&quot;version&quot;:&quot;8.4.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;right&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:true,&quot;bookmark&quot;:{&quot;enable&quot;:true,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:true,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;},&quot;path&quot;:&quot;&#x2F;search.xml&quot;,&quot;localsearch&quot;:{&quot;enable&quot;:true,&quot;trigger&quot;:&quot;auto&quot;,&quot;top_n_per_article&quot;:1,&quot;unescape&quot;:false,&quot;preload&quot;:false}}</script>
<meta name="description" content="本文为学习笔记，对应视频教程来自黑马程序员Hive教程 Hive部署Mysql 安装卸载Centos7自带mariadb和mysql12345[root@hadoop102 ~]# rpm -qa | grep mariadbmariadb-libs-5.5.60-1.el7_5.x86_64[root@hadoop102 ~]# rpm -e mariadb-libs-5.5.60-1.el7_">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop（三）：Hive">
<meta property="og:url" content="http://example.com/2022/05/11/Hadoop%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AHive/index.html">
<meta property="og:site_name" content="Eitan&#39;s Blog">
<meta property="og:description" content="本文为学习笔记，对应视频教程来自黑马程序员Hive教程 Hive部署Mysql 安装卸载Centos7自带mariadb和mysql12345[root@hadoop102 ~]# rpm -qa | grep mariadbmariadb-libs-5.5.60-1.el7_5.x86_64[root@hadoop102 ~]# rpm -e mariadb-libs-5.5.60-1.el7_">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220512093654.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220512170427.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220512173124.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220512194842.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220512195058.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220513231016.png">
<meta property="article:published_time" content="2022-05-11T08:58:11.118Z">
<meta property="article:modified_time" content="2022-06-02T16:43:55.782Z">
<meta property="article:author" content="Eitan">
<meta property="article:tag" content="hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220512093654.png">


<link rel="canonical" href="http://example.com/2022/05/11/Hadoop%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AHive/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:false,&quot;isPost&quot;:true,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:true,&quot;permalink&quot;:&quot;http:&#x2F;&#x2F;example.com&#x2F;2022&#x2F;05&#x2F;11&#x2F;Hadoop%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AHive&#x2F;&quot;,&quot;path&quot;:&quot;2022&#x2F;05&#x2F;11&#x2F;Hadoop（三）：Hive&#x2F;&quot;,&quot;title&quot;:&quot;Hadoop（三）：Hive&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>Hadoop（三）：Hive | Eitan's Blog</title><script src="/js/config.js"></script>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">
    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Eitan's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive%E9%83%A8%E7%BD%B2"><span class="nav-number">1.</span> <span class="nav-text">Hive部署</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Mysql-%E5%AE%89%E8%A3%85"><span class="nav-number">1.1.</span> <span class="nav-text">Mysql 安装</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8D%B8%E8%BD%BDCentos7%E8%87%AA%E5%B8%A6mariadb%E5%92%8Cmysql"><span class="nav-number">1.1.1.</span> <span class="nav-text">卸载Centos7自带mariadb和mysql</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#mysql%E5%AE%89%E8%A3%85%E4%BB%8B%E8%B4%A8%E4%B8%8B%E8%BD%BD"><span class="nav-number">1.1.2.</span> <span class="nav-text">mysql安装介质下载</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%A7%A3%E5%8E%8B%E5%AE%89%E8%A3%85%E4%BB%8B%E8%B4%A8"><span class="nav-number">1.1.3.</span> <span class="nav-text">解压安装介质</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%BB%BA%E7%AB%8B%E7%94%A8%E6%88%B7%E5%92%8C%E7%BB%84%E5%B9%B6%E5%88%9B%E5%BB%BA%E7%9B%B8%E5%85%B3%E7%9B%AE%E5%BD%95"><span class="nav-number">1.1.4.</span> <span class="nav-text">建立用户和组并创建相关目录</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="nav-number">1.1.5.</span> <span class="nav-text">配置环境变量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%89%E8%A3%85%E4%BE%9D%E8%B5%96%E5%8C%85"><span class="nav-number">1.1.6.</span> <span class="nav-text">安装依赖包</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96MySQL"><span class="nav-number">1.1.7.</span> <span class="nav-text">初始化MySQL</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive-%E5%AE%89%E8%A3%85-%E8%BF%9C%E7%A8%8B%E6%A8%A1%E5%BC%8F"><span class="nav-number">1.2.</span> <span class="nav-text">Hive 安装 - 远程模式</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Hive%E5%AE%89%E8%A3%85%E4%BB%8B%E8%B4%A8%E7%9A%84%E4%B8%8B%E8%BD%BD%E4%B8%8E%E8%A7%A3%E5%8E%8B"><span class="nav-number">1.2.1.</span> <span class="nav-text">Hive安装介质的下载与解压</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%A7%A3%E5%86%B3hadoop%E3%80%81hive%E4%B9%8B%E9%97%B4guava%E7%89%88%E6%9C%AC%E5%B7%AE%E5%BC%82"><span class="nav-number">1.2.2.</span> <span class="nav-text">解决hadoop、hive之间guava版本差异</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%B7%BB%E5%8A%A0mysql-jdbc%E9%A9%B1%E5%8A%A8"><span class="nav-number">1.2.3.</span> <span class="nav-text">添加mysql jdbc驱动</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9hive%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E6%96%87%E4%BB%B6"><span class="nav-number">1.2.4.</span> <span class="nav-text">修改hive环境变量文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%96%B0%E5%A2%9Ehive-site-xml"><span class="nav-number">1.2.5.</span> <span class="nav-text">新增hive-site.xml</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96metadata"><span class="nav-number">1.2.6.</span> <span class="nav-text">初始化metadata</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%90%AF%E5%8A%A8-hive"><span class="nav-number">1.2.7.</span> <span class="nav-text">启动 hive</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8-Hive-Beeline-Client-%E8%BF%9E%E6%8E%A5"><span class="nav-number">1.3.</span> <span class="nav-text">使用 Hive Beeline Client 连接</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Hive%E6%9C%8D%E5%8A%A1%E5%92%8C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%85%B3%E7%B3%BB%E6%A2%B3%E7%90%86"><span class="nav-number">1.3.1.</span> <span class="nav-text">Hive服务和客户端关系梳理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Hive%E6%9C%8D%E5%8A%A1%E8%A7%84%E5%88%92%E9%83%A8%E7%BD%B2"><span class="nav-number">1.3.2.</span> <span class="nav-text">Hive服务规划部署</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">1.3.3.</span> <span class="nav-text">修改配置文件</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%96%E5%86%99hive%E5%90%AF%E5%8A%A8%E5%81%9C%E6%AD%A2%E8%84%9A%E6%9C%AC"><span class="nav-number">1.4.</span> <span class="nav-text">编写hive启动停止脚本</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89%E8%AF%AD%E8%A8%80%EF%BC%88DDL%EF%BC%89"><span class="nav-number">2.</span> <span class="nav-text">Hive 的数据定义语言（DDL）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%8C%E6%95%B4%E5%BB%BA%E8%A1%A8%E8%AF%AD%E6%B3%95%E6%A0%91"><span class="nav-number">2.1.</span> <span class="nav-text">完整建表语法树</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">2.2.</span> <span class="nav-text">Hive数据类型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6%E6%9C%BA%E5%88%B6"><span class="nav-number">2.3.</span> <span class="nav-text">Hive读写文件机制</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Hive%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6%E6%B5%81%E7%A8%8B"><span class="nav-number">2.3.1.</span> <span class="nav-text">Hive读写文件流程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#SerDe%E6%A6%82%E5%BF%B5%E5%8F%8A%E7%9B%B8%E5%85%B3%E8%AF%AD%E6%B3%95"><span class="nav-number">2.3.2.</span> <span class="nav-text">SerDe概念及相关语法</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E8%B7%AF%E5%BE%84"><span class="nav-number">2.4.</span> <span class="nav-text">Hive数据存储路径</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%BB%98%E8%AE%A4%E5%AD%98%E5%82%A8%E8%B7%AF%E5%BE%84"><span class="nav-number">2.4.1.</span> <span class="nav-text">默认存储路径</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8C%87%E5%AE%9A%E5%AD%98%E5%82%A8%E8%B7%AF%E5%BE%84"><span class="nav-number">2.4.2.</span> <span class="nav-text">指定存储路径</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%83%E4%B9%A0"><span class="nav-number">2.5.</span> <span class="nav-text">练习</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8E%9F%E7%94%9F%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%BB%BA%E8%A1%A8%E7%BB%83%E4%B9%A0"><span class="nav-number">2.5.1.</span> <span class="nav-text">原生数据类型建表练习</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A4%8D%E6%9D%82%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%BB%BA%E8%A1%A8%E7%BB%83%E4%B9%A0"><span class="nav-number">2.5.2.</span> <span class="nav-text">复杂数据类型建表练习</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive%E5%86%85%E3%80%81%E5%A4%96%E9%83%A8%E8%A1%A8"><span class="nav-number">2.6.</span> <span class="nav-text">Hive内、外部表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="nav-number">2.7.</span> <span class="nav-text">Hive分区表</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%9D%99%E6%80%81%E5%88%86%E5%8C%BA"><span class="nav-number">2.7.1.</span> <span class="nav-text">静态分区</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8A%A8%E6%80%81%E5%88%86%E5%8C%BA"><span class="nav-number">2.7.2.</span> <span class="nav-text">动态分区</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive%E5%88%86%E6%A1%B6%E8%A1%A8"><span class="nav-number">2.8.</span> <span class="nav-text">Hive分桶表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive%E4%BA%8B%E5%8A%A1%E8%A1%A8"><span class="nav-number">2.9.</span> <span class="nav-text">Hive事务表</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Hive%E4%BA%8B%E5%8A%A1%E8%A1%A8%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"><span class="nav-number">2.9.1.</span> <span class="nav-text">Hive事务表的局限性</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Hive%E4%BA%8B%E5%8A%A1%E8%A1%A8%E5%AE%9E%E8%B7%B5"><span class="nav-number">2.9.2.</span> <span class="nav-text">Hive事务表实践</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive%E8%A7%86%E5%9B%BE"><span class="nav-number">2.10.</span> <span class="nav-text">Hive视图</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A6%82%E5%BF%B5"><span class="nav-number">2.10.1.</span> <span class="nav-text">概念</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%A7%86%E5%9B%BE%E8%AF%AD%E6%B3%95"><span class="nav-number">2.10.2.</span> <span class="nav-text">视图语法</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE"><span class="nav-number">2.11.</span> <span class="nav-text">Hive物化视图</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE%E3%80%81%E8%A7%86%E5%9B%BE%E5%8C%BA%E5%88%AB"><span class="nav-number">2.11.1.</span> <span class="nav-text">物化视图、视图区别</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE%E8%AF%AD%E6%B3%95"><span class="nav-number">2.11.2.</span> <span class="nav-text">物化视图语法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B"><span class="nav-number">2.11.3.</span> <span class="nav-text">案例</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Database%EF%BC%88%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%89DDL%E6%93%8D%E4%BD%9C"><span class="nav-number">2.12.</span> <span class="nav-text">Database（数据库）DDL操作</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Create-Database"><span class="nav-number">2.12.1.</span> <span class="nav-text">Create Database</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Describe-Database"><span class="nav-number">2.12.2.</span> <span class="nav-text">Describe Database</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Use-Database"><span class="nav-number">2.12.3.</span> <span class="nav-text">Use Database</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Drop-Database"><span class="nav-number">2.12.4.</span> <span class="nav-text">Drop Database</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Alter-Database"><span class="nav-number">2.12.5.</span> <span class="nav-text">Alter Database</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Table%EF%BC%88%E8%A1%A8%EF%BC%89DDL%E6%93%8D%E4%BD%9C"><span class="nav-number">2.13.</span> <span class="nav-text">Table（表）DDL操作</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Describe-Table"><span class="nav-number">2.13.1.</span> <span class="nav-text">Describe Table</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Drop-Table"><span class="nav-number">2.13.2.</span> <span class="nav-text">Drop Table</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Truncate-Table"><span class="nav-number">2.13.3.</span> <span class="nav-text">Truncate Table</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Alter-Table"><span class="nav-number">2.13.4.</span> <span class="nav-text">Alter Table</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Partition%EF%BC%88%E5%88%86%E5%8C%BA%EF%BC%89DDL%E6%93%8D%E4%BD%9C"><span class="nav-number">2.14.</span> <span class="nav-text">Partition（分区）DDL操作</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Add-Partition"><span class="nav-number">2.14.1.</span> <span class="nav-text">Add Partition</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Rename-Partition"><span class="nav-number">2.14.2.</span> <span class="nav-text">Rename Partition</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Delete-Partition"><span class="nav-number">2.14.3.</span> <span class="nav-text">Delete Partition</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Msck-Partition"><span class="nav-number">2.14.4.</span> <span class="nav-text">Msck Partition</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Alter-Partition"><span class="nav-number">2.14.5.</span> <span class="nav-text">Alter Partition</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive-Show%E6%98%BE%E7%A4%BA%E8%AF%AD%E6%B3%95"><span class="nav-number">2.15.</span> <span class="nav-text">Hive Show显示语法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-%E7%9A%84%E6%95%B0%E6%8D%AE%E6%93%8D%E7%BA%B5%E8%AF%AD%E8%A8%80%EF%BC%88DML%EF%BC%89"><span class="nav-number">3.</span> <span class="nav-text">Hive 的数据操纵语言（DML）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#DML-LOAD%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE"><span class="nav-number">3.1.</span> <span class="nav-text">DML-LOAD加载数据</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#LOAD%E8%AF%AD%E6%B3%95"><span class="nav-number">3.1.1.</span> <span class="nav-text">LOAD语法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B-1"><span class="nav-number">3.1.2.</span> <span class="nav-text">案例</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Hive3-0-Load%E6%96%B0%E7%89%B9%E6%80%A7"><span class="nav-number">3.1.3.</span> <span class="nav-text">Hive3.0 Load新特性</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DML-Insert%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="nav-number">3.2.</span> <span class="nav-text">DML-Insert插入数据</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#insert-select"><span class="nav-number">3.2.1.</span> <span class="nav-text">insert + select</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#multiple-inserts%E5%A4%9A%E9%87%8D%E6%8F%92%E5%85%A5"><span class="nav-number">3.2.2.</span> <span class="nav-text">multiple inserts多重插入</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#dynamic-partition-insert%E5%8A%A8%E6%80%81%E5%88%86%E5%8C%BA%E6%8F%92%E5%85%A5"><span class="nav-number">3.2.3.</span> <span class="nav-text">dynamic partition insert动态分区插入</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#insert-directory%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE"><span class="nav-number">3.2.4.</span> <span class="nav-text">insert + directory导出数据</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive-Transaction%E4%BA%8B%E5%8A%A1"><span class="nav-number">3.3.</span> <span class="nav-text">Hive Transaction事务</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="nav-number">3.3.1.</span> <span class="nav-text">实现原理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%90%88%E5%B9%B6%E5%99%A8-Compactor"><span class="nav-number">3.3.2.</span> <span class="nav-text">合并器(Compactor)</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DML-Update%E3%80%81Delete%E6%9B%B4%E6%96%B0%E3%80%81%E5%88%A0%E9%99%A4%E6%95%B0%E6%8D%AE"><span class="nav-number">3.4.</span> <span class="nav-text">DML-Update、Delete更新、删除数据</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80%EF%BC%88DQL%EF%BC%89"><span class="nav-number">4.</span> <span class="nav-text">Hive 的数据查询语言（DQL）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AF%AD%E6%B3%95%E6%A0%91"><span class="nav-number">4.0.1.</span> <span class="nav-text">语法树</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F"><span class="nav-number">4.0.2.</span> <span class="nav-text">执行顺序</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#ORDER-BY"><span class="nav-number">4.0.3.</span> <span class="nav-text">ORDER BY</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#CLUSTER-BY"><span class="nav-number">4.0.4.</span> <span class="nav-text">CLUSTER BY</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#DISTRIBUTE-BY-SORT-BY"><span class="nav-number">4.0.5.</span> <span class="nav-text">DISTRIBUTE BY +SORT BY</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Union%E8%81%94%E5%90%88%E6%9F%A5%E8%AF%A2"><span class="nav-number">4.0.6.</span> <span class="nav-text">Union联合查询</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Common-Table-Expressions%EF%BC%88CTE%EF%BC%89"><span class="nav-number">4.0.7.</span> <span class="nav-text">Common Table Expressions（CTE）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#join%E8%BF%9E%E6%8E%A5%E6%9F%A5%E8%AF%A2"><span class="nav-number">4.0.8.</span> <span class="nav-text">join连接查询</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Eitan"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Eitan</p>
  <div class="site-description" itemprop="description">blog用于记忆，大脑擅长思考</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">47</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/eitan-blog" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;eitan-blog" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:eitan_blog@163.com" title="E-Mail → mailto:eitan_blog@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>




        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/yourname" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/05/11/Hadoop%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AHive/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Eitan">
      <meta itemprop="description" content="blog用于记忆，大脑擅长思考">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Eitan's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop（三）：Hive
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-11 16:58:11" itemprop="dateCreated datePublished" datetime="2022-05-11T16:58:11+08:00">2022-05-11</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2022-06-03 00:43:55" itemprop="dateModified" datetime="2022-06-03T00:43:55+08:00">2022-06-03</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Big-Data/" itemprop="url" rel="index"><span itemprop="name">Big Data</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>35k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>32 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>本文为学习笔记，对应视频教程来自<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1L5411u7ae">黑马程序员Hive教程</a></p>
<h3 id="Hive部署"><a href="#Hive部署" class="headerlink" title="Hive部署"></a>Hive部署</h3><h4 id="Mysql-安装"><a href="#Mysql-安装" class="headerlink" title="Mysql 安装"></a>Mysql 安装</h4><h5 id="卸载Centos7自带mariadb和mysql"><a href="#卸载Centos7自带mariadb和mysql" class="headerlink" title="卸载Centos7自带mariadb和mysql"></a>卸载Centos7自带mariadb和mysql</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# rpm -qa | grep mariadb</span><br><span class="line">mariadb-libs-5.5.60-1.el7_5.x86_64</span><br><span class="line">[root@hadoop102 ~]# rpm -e mariadb-libs-5.5.60-1.el7_5.x86_64 --nodeps</span><br><span class="line"><span class="meta">#</span><span class="bash"> 最小化安装不会自带MySQL</span></span><br><span class="line">[root@hadoop102 ~]# rpm -e --nodeps $(rpm -qa | grep mysql)</span><br></pre></td></tr></table></figure>

<h5 id="mysql安装介质下载"><a href="#mysql安装介质下载" class="headerlink" title="mysql安装介质下载"></a>mysql安装介质下载</h5><p><strong>官网下载地址：</strong><a target="_blank" rel="noopener" href="https://downloads.mysql.com/archives/community/"><strong>MySQL Product Archives</strong></a></p>
<table>
<thead>
<tr>
<th>Product Version</th>
<th>Operating System</th>
<th>OS Version</th>
</tr>
</thead>
<tbody><tr>
<td>5.7.20</td>
<td>Linux - Generic</td>
<td>Linux - Generic(glibc 2.12)(x86,64-bit)</td>
</tr>
</tbody></table>
<h5 id="解压安装介质"><a href="#解压安装介质" class="headerlink" title="解压安装介质"></a>解压安装介质</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/software/</span><br><span class="line">[root@hadoop102 software]# tar -zxf mysql-5.7.20-linux-glibc2.12-x86_64.tar.gz</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将解压出的文件夹名称修改为mysql-5.7.20</span></span><br><span class="line">[root@hadoop102 software]# mv mysql-5.7.20-linux-glibc2.12-x86_64 ../module/mysql-5.7.20</span><br></pre></td></tr></table></figure>

<h5 id="建立用户和组并创建相关目录"><a href="#建立用户和组并创建相关目录" class="headerlink" title="建立用户和组并创建相关目录"></a>建立用户和组并创建相关目录</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 mysql-5.7.20]# groupadd mysql</span><br><span class="line">[root@hadoop102 mysql-5.7.20]# useradd -r -g mysql -s /bin/false mysql</span><br><span class="line"></span><br><span class="line">[root@hadoop102 mysql-5.7.20]# mkdir -p /data/mysql</span><br><span class="line">[root@hadoop102 mysql-5.7.20]# chown -R mysql:mysql /data</span><br><span class="line">[root@hadoop102 mysql-5.7.20]# chmod 750 /data</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h5 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# vim /etc/profile.d/my_env.sh </span><br><span class="line"><span class="meta">#</span><span class="bash">MYSQL_HOME</span></span><br><span class="line">export MYSQL_HOME=/opt/module/mysql-5.7.20</span><br><span class="line">export PATH=$PATH:$MYSQL_HOME/bin</span><br><span class="line"></span><br><span class="line">[root@hadoop102 ~]# source /etc/profile</span><br></pre></td></tr></table></figure>

<h5 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# yum install libaio</span><br></pre></td></tr></table></figure>

<h5 id="初始化MySQL"><a href="#初始化MySQL" class="headerlink" title="初始化MySQL"></a>初始化MySQL</h5><ol>
<li><p>初始化创建mysql数据库</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# mysqld --initialize --user=mysql --basedir=/opt/module/mysql-5.7.20/ --datadir=/data/mysql/</span><br><span class="line">2022-05-11T10:50:24.777743Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).</span><br><span class="line">2022-05-11T10:50:25.027412Z 0 [Warning] InnoDB: New log files created, LSN=45790</span><br><span class="line">2022-05-11T10:50:25.068499Z 0 [Warning] InnoDB: Creating foreign key constraint system tables.</span><br><span class="line">2022-05-11T10:50:25.139430Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 29be3489-d118-11ec-ba45-000c2900c11d.</span><br><span class="line">2022-05-11T10:50:25.140670Z 0 [Warning] Gtid table is not ready to be used. Table &#x27;mysql.gtid_executed&#x27; cannot be opened.</span><br><span class="line">2022-05-11T10:50:25.141518Z 1 [Note] A temporary password is generated for root@localhost: L2)cw18vE8lw</span><br></pre></td></tr></table></figure></li>
<li><p>配置mysql.cnf文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 找到配置文件所在位置</span></span><br><span class="line">[root@hadoop102 ~]# mysql --help | grep cnf</span><br><span class="line">                      order of preference, my.cnf, $MYSQL_TCP_PORT,</span><br><span class="line">/etc/my.cnf /etc/mysql/my.cnf /usr/local/mysql/etc/my.cnf /opt/module/mysql-5.7.20/my.cnf ~/.my.cnf </span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 编辑配置文件</span></span><br><span class="line">[root@hadoop102 ~]# vim /etc/my.cnf</span><br><span class="line">[mysqld]</span><br><span class="line">user=mysql</span><br><span class="line">port=3306</span><br><span class="line">basedir=/opt/module/mysql-5.7.20</span><br><span class="line">datadir=/data/mysql</span><br><span class="line">server_id=1</span><br><span class="line">socket=/tmp/mysql.sock</span><br><span class="line">[mysql]</span><br><span class="line">socket=/tmp/mysql.sock</span><br></pre></td></tr></table></figure></li>
<li><p>配置mysql服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# vim /usr/lib/systemd/system/mysqld.service</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=MySQL Server</span><br><span class="line">Documentation=man:mysqld(8)</span><br><span class="line">Documentation=http://dev.mysql.com/doc/refman/en/using-systemd.html</span><br><span class="line">After=network.target</span><br><span class="line">After=syslog.target</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">[Service]</span><br><span class="line">User=mysql</span><br><span class="line">Group=mysql</span><br><span class="line">ExecStart=/opt/module/mysql-5.7.20/bin/mysqld --defaults-file=/etc/my.cnf</span><br><span class="line">LimitNOFILE = 5000</span><br></pre></td></tr></table></figure></li>
<li><p>启动服务并修改密码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# systemctl start mysqld</span><br><span class="line"></span><br><span class="line">[root@hadoop102 ~]# mysql -uroot -p</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改密码</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> ALTER USER USER() IDENTIFIED BY <span class="string">&#x27;root&#x27;</span>;</span></span><br></pre></td></tr></table></figure></li>
<li><p>授权允许远程访问</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看MySQL当前远程访问权限配置</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> use mysql;</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> SELECT User,authentication_string,Host FROM user;</span></span><br><span class="line">+---------------+-------------------------------------------+-----------+</span><br><span class="line">| User          | authentication_string                     | Host      |</span><br><span class="line">+---------------+-------------------------------------------+-----------+</span><br><span class="line">| root          | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | localhost |</span><br><span class="line">| mysql.session | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | localhost |</span><br><span class="line">| mysql.sys     | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | localhost |</span><br><span class="line">+---------------+-------------------------------------------+-----------+</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改权限，password 为密码</span></span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;password&#x27; WITH GRANT OPTION;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 从mysql数据库的grant表中重新加载权限数据</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> FLUSH PRIVILEGES;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="Hive-安装-远程模式"><a href="#Hive-安装-远程模式" class="headerlink" title="Hive 安装 - 远程模式"></a>Hive 安装 - 远程模式</h4><h5 id="Hive安装介质的下载与解压"><a href="#Hive安装介质的下载与解压" class="headerlink" title="Hive安装介质的下载与解压"></a>Hive安装介质的下载与解压</h5><p><strong>官网下载地址：</strong><a target="_blank" rel="noopener" href="https://hive.apache.org/downloads.html"><strong>Apache Hive Downloads</strong></a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/software/</span><br><span class="line">[root@hadoop102 software]# tar -zxf apache-hive-3.1.3-bin.tar.gz </span><br><span class="line">[root@hadoop102 software]# mv apache-hive-3.1.3-bin ../module/apache-hive-3.1.3</span><br></pre></td></tr></table></figure>

<h5 id="解决hadoop、hive之间guava版本差异"><a href="#解决hadoop、hive之间guava版本差异" class="headerlink" title="解决hadoop、hive之间guava版本差异"></a>解决hadoop、hive之间guava版本差异</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 删除 hive 中低版本的 jar 包</span></span><br><span class="line">[root@hadoop102 ~]# cd /opt/module/apache-hive-3.1.3/</span><br><span class="line">[root@hadoop102 apache-hive-3.1.3]# rm -rf lib/guava-19.0.jar </span><br><span class="line"><span class="meta">#</span><span class="bash"> 复制 hadoop 中高版本的 jar 包到 hive 的 lib 目录下</span></span><br><span class="line">[root@hadoop102 apache-hive-3.1.3]# cp /opt/module/hadoop-3.3.2/share/hadoop/common/lib/guava-27.0-jre.jar ./lib/</span><br></pre></td></tr></table></figure>

<h5 id="添加mysql-jdbc驱动"><a href="#添加mysql-jdbc驱动" class="headerlink" title="添加mysql jdbc驱动"></a>添加mysql jdbc驱动</h5><p><strong>官网下载地址：</strong><a target="_blank" rel="noopener" href="https://dev.mysql.com/downloads/">MySQL Community Downloads</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@hadoop102 eitan]# cd /opt/software/</span><br><span class="line">[root@hadoop102 software]# tar -zxf mysql-connector-java-8.0.29.tar.gz </span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加mysql jdbc驱动到hive安装包lib/文件下</span></span><br><span class="line">[root@hadoop102 software]# cd mysql-connector-java-8.0.29</span><br><span class="line">[root@hadoop102 mysql-connector-java-8.0.29]# cp mysql-connector-java-8.0.29.jar /opt/module/apache-hive-3.1.3/lib/</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="left">Connector/J version</th>
<th align="left">JDBC version</th>
<th align="left">MySQL Server version</th>
<th align="left">JRE Required</th>
<th align="left">JDK Required for Compilation</th>
<th align="left">Status</th>
</tr>
</thead>
<tbody><tr>
<td align="left">5.1</td>
<td align="left">3.0, 4.0, 4.1, 4.2</td>
<td align="left">5.61, 5.71, 8.01</td>
<td align="left">JRE 5 or higher1</td>
<td align="left">JDK 5.0 AND JDK 8.0 or higher2, 3</td>
<td align="left">General availability</td>
</tr>
<tr>
<td align="left">8.0</td>
<td align="left">4.2</td>
<td align="left">5.6, 5.7, 8.0</td>
<td align="left">JRE 8 or higher</td>
<td align="left">JDK 8.0 or higher2</td>
<td align="left">General availability. Recommended version.</td>
</tr>
</tbody></table>
<blockquote>
<p>说明：mysql jdbc 的java驱动只有两个版本，且两个版本都支持mysql-5.7。官方推荐使用8.0版本。</p>
</blockquote>
<h5 id="修改hive环境变量文件"><a href="#修改hive环境变量文件" class="headerlink" title="修改hive环境变量文件"></a>修改hive环境变量文件</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/module/apache-hive-3.1.3/conf/</span><br><span class="line">[root@hadoop102 conf]# cp hive-env.sh.template hive-env.sh</span><br><span class="line">[root@hadoop102 conf]# vim hive-env.sh</span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-3.3.2</span><br><span class="line">export HIVE_CONF_DIR=/opt/module/apache-hive-3.1.3/conf</span><br><span class="line">export HIVE_AUX_JARS_PATH=/opt/module/apache-hive-3.1.3/lib</span><br></pre></td></tr></table></figure>

<h5 id="新增hive-site-xml"><a href="#新增hive-site-xml" class="headerlink" title="新增hive-site.xml"></a>新增hive-site.xml</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 conf]# vim hive-site.xml</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- 存储元数据mysql相关配置 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;jdbc:mysql://hadoop102:3306/hive?createDatabaseIfNotExist=true&amp;amp;useSSL=false&amp;amp;useUnicode=true&amp;amp;characterEncoding=UTF-8&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;com.mysql.cj.jdbc.Driver&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- Bind host on which to run the HiveServer2 Thrift interface --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hadoop102&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 远程模式部署metastore服务地址 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.metastore.uris&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;thrift://hadoop102:9083&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- 关闭元数据存储授权  --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.metastore.event.db.notification.api.auth&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 关闭元数据存储版本的验证 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.metastore.schema.verification&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<h5 id="初始化metadata"><a href="#初始化metadata" class="headerlink" title="初始化metadata"></a>初始化metadata</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/module/apache-hive-3.1.3/</span><br><span class="line">[root@hadoop102 apache-hive-3.1.3]# ./bin/schematool -initSchema -dbType mysql -verbos</span><br></pre></td></tr></table></figure>

<blockquote>
<p>校验是否成功：MySQL中创建hive数据库并持有74张表</p>
</blockquote>
<h5 id="启动-hive"><a href="#启动-hive" class="headerlink" title="启动 hive"></a>启动 hive</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动 hadoop 集群，hadoop 集群启动脚本在 Hadoop（一）：集群搭建.md</span></span><br><span class="line">[eitan@hadoop102 ~]$ myhadoop.sh start</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动 Metastore</span></span><br><span class="line">[eitan@hadoop102 ~]$ nohup /opt/module/apache-hive-3.1.3/bin/hive --service metastore &amp;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动 Hive</span></span><br><span class="line">[eitan@hadoop102 ~]$ /opt/module/apache-hive-3.1.3/bin/hive</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证是否启动成功</span></span><br><span class="line"><span class="meta">hive&gt;</span><span class="bash"> show databases;</span></span><br><span class="line">OK</span><br><span class="line">default</span><br><span class="line">Time taken: 0.52 seconds, Fetched: 1 row(s)</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 前台启动开启debug日志</span></span><br><span class="line">/opt/module/apache-hive-3.1.3/bin/hive --service metastore  --hiveconf hive.root.logger=DEBUG,console</span><br></pre></td></tr></table></figure>

<h4 id="使用-Hive-Beeline-Client-连接"><a href="#使用-Hive-Beeline-Client-连接" class="headerlink" title="使用 Hive Beeline Client 连接"></a>使用 Hive Beeline Client 连接</h4><h5 id="Hive服务和客户端关系梳理"><a href="#Hive服务和客户端关系梳理" class="headerlink" title="Hive服务和客户端关系梳理"></a>Hive服务和客户端关系梳理</h5><p>HiveServer2通过Metastore服务读写元数据。所以在远程模式下，启动HiveServer2之前必须先首先启动metastore服务。远程模式下，Beeline客户端只能通过HiveServer2服务访问Hive。而Hive Client是通过Metastore服务访问的。具体关系如下：</p>
<p><img src="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220512093654.png" alt="image-20220512093652882"></p>
<h5 id="Hive服务规划部署"><a href="#Hive服务规划部署" class="headerlink" title="Hive服务规划部署"></a>Hive服务规划部署</h5><table>
<thead>
<tr>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>Metastore<br />Mysql</td>
<td>HiveServer2</td>
<td>Beeline Client</td>
</tr>
</tbody></table>
<h5 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h5><ol>
<li><p>Metastore需要知道HiveServer2运行位置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[eitan@hadoop102 ~]$ sudo vim /opt/module/apache-hive-3.1.3/conf/hive-site.xml</span><br><span class="line"><span class="meta">	#</span><span class="bash"> 修改&lt;value&gt;为hadoop103</span></span><br><span class="line">    &lt;!-- Bind host on which to run the HiveServer2 Thrift interface --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hadoop103&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br></pre></td></tr></table></figure></li>
<li><p>HiveServer2需要知道Metastore运行位置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[eitan@hadoop102 ~]$ sudo vim /opt/module/apache-hive-3.1.3/conf/hive-site.xml</span><br><span class="line">    # 确认 metastore 启动在 hadoop102 并监听9083接口</span><br><span class="line">    &lt;!-- 远程模式部署metastore服务地址 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.metastore.uris&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;thrift://hadoop102:9083&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br></pre></td></tr></table></figure></li>
<li><p>开启各项服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动MySQL</span></span><br><span class="line">[eitan@hadoop102 ~]$ systemctl start mysqld</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动Hadoop集群</span></span><br><span class="line">[eitan@hadoop102 ~]$ myhadoop.sh start</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动metastore服务，只需先启动了MySQL就行与Hadoop无关</span></span><br><span class="line">[eitan@hadoop102 ~]$ /opt/module/apache-hive-3.1.3/bin/hive --service metastore</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动hiveserver2,需要提前启动Hadoop</span></span><br><span class="line">[eitan@hadoop103 ~]$ /opt/module/apache-hive-3.1.3/bin/hiveserver2 </span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动beeline，并连接hiveserver2</span></span><br><span class="line">[eitan@hadoop104 ~]$ /opt/module/apache-hive-3.1.3/bin/beeline</span><br><span class="line"><span class="meta">beeline&gt;</span><span class="bash"> ! connect jdbc:hive2://hadoop103:10000</span></span><br><span class="line">Connecting to jdbc:hive2://hadoop103:10000</span><br><span class="line">Enter username for jdbc:hive2://hadoop103:10000: eitan</span><br><span class="line">Enter password for jdbc:hive2://hadoop103:10000: </span><br><span class="line">Connected to: Apache Hive (version 3.1.3)</span><br><span class="line">Driver: Hive JDBC (version 3.1.3)</span><br><span class="line">Transaction isolation: TRANSACTION_REPEATABLE_READ</span><br><span class="line">0: jdbc:hive2://hadoop103:10000&gt; </span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="编写hive启动停止脚本"><a href="#编写hive启动停止脚本" class="headerlink" title="编写hive启动停止脚本"></a>编写hive启动停止脚本</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[eitan@hadoop102 ~]$ vim bin/myhive.sh </span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;No Args Input...&quot;</span><br><span class="line">    exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)</span><br><span class="line">    echo &quot;================ 启动 Hive ================&quot;</span><br><span class="line">    echo &quot;---------------- 启动 metastore ----------------&quot;</span><br><span class="line">    ssh hadoop102 &quot;nohup /opt/module/apache-hive-3.1.3/bin/hive --service metastore &gt; /home/eitan/log/metastore.out 2&gt;&amp;1 &amp;&quot;</span><br><span class="line">    echo &quot;---------------- 启动 hiveserver2 ----------------&quot;</span><br><span class="line">    ssh hadoop103 &quot;nohup /opt/module/apache-hive-3.1.3/bin/hiveserver2 &gt; /home/eitan/log/hiveserver2.out 2&gt;&amp;1 &amp;&quot;</span><br><span class="line">;;</span><br><span class="line">&quot;stop&quot;)</span><br><span class="line">    echo &quot;================ 关闭 Hive ================&quot;</span><br><span class="line">    echo &quot;---------------- 关闭 metastore ----------------&quot;</span><br><span class="line">    ssh hadoop102 &quot;ps -ef | grep metastore | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9&quot;</span><br><span class="line">    echo &quot;---------------- 关闭 hiveserver2 ----------------&quot;</span><br><span class="line">    ssh hadoop103 &quot;ps -ef | grep hiveserver2 | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9&quot;</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">    echo &quot;Input Args Error...&quot;</span><br><span class="line">;;</span><br><span class="line">esac</span><br><span class="line"></span><br><span class="line">[eitan@hadoop102 ~]$ chmod +x bin/myhive.sh </span><br><span class="line">[eitan@hadoop102 ~]$ xsync bin/myhive.sh </span><br></pre></td></tr></table></figure>

<h3 id="Hive-的数据定义语言（DDL）"><a href="#Hive-的数据定义语言（DDL）" class="headerlink" title="Hive 的数据定义语言（DDL）"></a>Hive 的数据定义语言（DDL）</h3><h4 id="完整建表语法树"><a href="#完整建表语法树" class="headerlink" title="完整建表语法树"></a>完整建表语法树</h4><p><img src="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220512170427.png" alt="image-20220512170423242"></p>
<blockquote>
<ul>
<li><p><strong>蓝色</strong>字体是建表语法的关键字，用于指定某些功能。</p>
</li>
<li><p>**[]**中括号的语法表示可选。</p>
</li>
<li><p>**|**表示使用的时候，左右语法二选一。</p>
</li>
<li><p>建表语句中的语法顺序要和上述语法规则保持一致。</p>
</li>
</ul>
</blockquote>
<h4 id="Hive数据类型"><a href="#Hive数据类型" class="headerlink" title="Hive数据类型"></a>Hive数据类型</h4><p>Hive中的数据类型指的是Hive表中的列字段类型。Hive数据类型整体分为两个类别：<strong>原生数据类型</strong>（primitive data type）和<strong>复杂数据类型</strong>（complex data type）。</p>
<p>原生数据类型包括：数值类型、时间类型、字符串类型、杂项数据类型；</p>
<p>复杂数据类型包括：array数组、map映射、struct结构、union联合体。</p>
<p>官方文档链接：<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types</a></p>
<h4 id="Hive读写文件机制"><a href="#Hive读写文件机制" class="headerlink" title="Hive读写文件机制"></a>Hive读写文件机制</h4><h5 id="Hive读写文件流程"><a href="#Hive读写文件流程" class="headerlink" title="Hive读写文件流程"></a>Hive读写文件流程</h5><p><strong>Hive读取文件机制</strong>：首先调用InputFormat（默认TextInputFormat），返回一条一条kv键值对记录（默认是一行对应一条记录）。然后调用SerDe（默认LazySimpleSerDe）的Deserializer，将一条记录中的value根据分隔符切分为各个字段。</p>
<p><strong>Hive写文件机制</strong>：将Row写入文件时，首先调用SerDe（默认LazySimpleSerDe）的Serializer将对象转换成字节序列，然后调用OutputFormat将数据写入HDFS文件中。</p>
<p><img src="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220512173124.png" alt="image-20220512173122549"></p>
<h5 id="SerDe概念及相关语法"><a href="#SerDe概念及相关语法" class="headerlink" title="SerDe概念及相关语法"></a>SerDe概念及相关语法</h5><p>SerDe是Serializer、Deserializer的简称，目的是用于序列化和反序列化。序列化是对象转化为字节码的过程；而反序列化是字节码转换为对象的过程。</p>
<p>在Hive的建表语句中，和SerDe相关的语法为：</p>
<p><img src="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220512194842.png" alt="image-20220512194839798"></p>
<blockquote>
<p>其中ROW FORMAT是语法关键字，DELIMITED和SERDE二选其一。</p>
<p>如果使用DELIMITED表示使用默认的LazySimpleSerDe类来处理数据。如果数据文件格式比较特殊可以使用ROW FORMAT SERDE serde_name指定其他的Serde类来处理数据,甚至支持用户自定义SerDe类。</p>
</blockquote>
<p>LazySimpleSerDe是Hive默认的序列化类，包含4种子语法，分别用于指定<strong>字段之间</strong>、<strong>集合元素之间</strong>、<strong>map映射 kv之间</strong>、<strong>换行</strong>的分隔符号：</p>
<p><img src="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220512195058.png" alt="image-20220512195056138"></p>
<blockquote>
<p>默认分隔符为 ‘\001’</p>
<table>
<thead>
<tr>
<th>二进制</th>
<th>十进制</th>
<th>十六进制</th>
<th>缩写</th>
</tr>
</thead>
<tbody><tr>
<td>0000 0001</td>
<td>1</td>
<td>01</td>
<td>SOH</td>
</tr>
</tbody></table>
</blockquote>
<h4 id="Hive数据存储路径"><a href="#Hive数据存储路径" class="headerlink" title="Hive数据存储路径"></a>Hive数据存储路径</h4><h5 id="默认存储路径"><a href="#默认存储路径" class="headerlink" title="默认存储路径"></a>默认存储路径</h5><p>Hive表默认存储路径是由${HIVE_HOME}/conf/hive-site.xml配置文件的hive.metastore.warehouse.dir属性指定。默认值是：/user/hive/warehouse。</p>
<h5 id="指定存储路径"><a href="#指定存储路径" class="headerlink" title="指定存储路径"></a>指定存储路径</h5><p>在Hive建表的时候，可以通过<strong>LOCATION语法来更改数据在HDFS上的存储路径</strong>，使得建表加载数据更加灵活方便。</p>
<p>语法：<strong>LOCATION ‘<hdfs_location>‘</strong></p>
<h4 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h4><h5 id="原生数据类型建表练习"><a href="#原生数据类型建表练习" class="headerlink" title="原生数据类型建表练习"></a>原生数据类型建表练习</h5><p><strong>需求：</strong>文件archer.txt中记录了手游《王者荣耀》射手的相关信息，内容如下所示，其中字段之间分隔符为制表符\t,要求在Hive中建表映射成功该文件。</p>
<figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>	后羿	<span class="number">5986</span>	<span class="number">1784</span>	<span class="number">396</span>	<span class="number">336</span>	<span class="comment">remotely	archer</span></span><br><span class="line"><span class="number">2</span>	马可波罗	<span class="number">5584</span>	<span class="number">200</span>	<span class="number">362</span>	<span class="number">344</span>	<span class="comment">remotely	archer</span></span><br><span class="line"><span class="number">3</span>	鲁班七号	<span class="number">5989</span>	<span class="number">1756</span>	<span class="number">400</span>	<span class="number">323</span>	<span class="comment">remotely	archer</span></span><br><span class="line"><span class="number">4</span>	李元芳	<span class="number">5725</span>	<span class="number">1770</span>	<span class="number">396</span>	<span class="number">340</span>	<span class="comment">remotely	archer</span></span><br><span class="line"><span class="number">5</span>	孙尚香	<span class="number">6014</span>	<span class="number">1756</span>	<span class="number">411</span>	<span class="number">346</span>	<span class="comment">remotely	archer</span></span><br><span class="line"><span class="number">6</span>	黄忠	<span class="number">5898</span>	<span class="number">1784</span>	<span class="number">403</span>	<span class="number">319</span>	<span class="comment">remotely	archer</span></span><br><span class="line"><span class="number">7</span>	狄仁杰	<span class="number">5710</span>	<span class="number">1770</span>	<span class="number">376</span>	<span class="number">338</span>	<span class="comment">remotely	archer</span></span><br><span class="line"><span class="number">8</span>	虞姬	<span class="number">5669</span>	<span class="number">1770</span>	<span class="number">407</span>	<span class="number">329</span>	<span class="comment">remotely	archer</span></span><br><span class="line"><span class="number">9</span>	成吉思汗	<span class="number">5799</span>	<span class="number">1742</span>	<span class="number">394</span>	<span class="number">329</span>	<span class="comment">remotely	archer</span></span><br><span class="line"><span class="number">10</span>	百里守约	<span class="number">5611</span>	<span class="number">1784</span>	<span class="number">410</span>	<span class="number">329</span>	<span class="comment">remotely	archer	assassin</span></span><br></pre></td></tr></table></figure>

<p>字段含义：id、name（英雄名称）、hp_max（最大生命）、mp_max（最大法力）、attack_max（最高物攻）、defense_max（最大物防）、attack_range（攻击范围）、role_main（主要定位）、role_assist（次要定位）</p>
<p><strong>实践：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t_archer (</span><br><span class="line">    id <span class="type">int</span> comment &quot;ID&quot;,</span><br><span class="line">    name string comment &quot;英雄名称&quot;,</span><br><span class="line">    hp_max <span class="type">int</span> comment &quot;最大生命&quot;,</span><br><span class="line">    mp_max <span class="type">int</span> comment &quot;最大法力&quot;,</span><br><span class="line">    attack_max <span class="type">int</span> comment &quot;最高物攻&quot;,</span><br><span class="line">    defense_max <span class="type">int</span> comment &quot;最大物防&quot;,</span><br><span class="line">    attack_range string comment &quot;攻击范围&quot;,</span><br><span class="line">    role_main string comment &quot;主要定位&quot;,</span><br><span class="line">    role_assist string comment &quot;次要定位&quot;</span><br><span class="line">) comment &quot;王者荣耀射手信息&quot;</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> &quot;\t&quot;;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 上传文件</span></span><br><span class="line">[eitan@hadoop102 ~]$ hadoop fs -put documents/txt/archer.txt /user/hive/warehouse/itcast.db/t_archer/</span><br></pre></td></tr></table></figure>

<h5 id="复杂数据类型建表练习"><a href="#复杂数据类型建表练习" class="headerlink" title="复杂数据类型建表练习"></a>复杂数据类型建表练习</h5><p><strong>需求：</strong>文件hot_hero_skin_price.txt中记录了手游《王者荣耀》热门英雄的相关皮肤价格信息，内容如下,要求在Hive中建表映射成功该文件。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">1</span>,孙悟空,<span class="number">53</span>,西部大镖客:<span class="number">288</span>-大圣娶亲:<span class="number">888</span>-全息碎片:<span class="number">0</span>-至尊宝:<span class="number">888</span>-地狱火:<span class="number">1688</span></span><br><span class="line"><span class="attribute">2</span>,鲁班七号,<span class="number">54</span>,木偶奇遇记:<span class="number">288</span>-福禄兄弟:<span class="number">288</span>-黑桃队长:<span class="number">60</span>-电玩小子:<span class="number">2288</span>-星空梦想:<span class="number">0</span></span><br><span class="line"><span class="attribute">3</span>,后裔,<span class="number">53</span>,精灵王:<span class="number">288</span>-阿尔法小队:<span class="number">588</span>-辉光之辰:<span class="number">888</span>-黄金射手座:<span class="number">1688</span>-如梦令:<span class="number">1314</span></span><br><span class="line"><span class="attribute">4</span>,铠,<span class="number">52</span>,龙域领主:<span class="number">288</span>-曙光守护者:<span class="number">1776</span></span><br><span class="line"><span class="attribute">5</span>,韩信,<span class="number">52</span>,飞衡:<span class="number">1788</span>-逐梦之影:<span class="number">888</span>-白龙吟:<span class="number">1188</span>-教廷特使:<span class="number">0</span>-街头霸王:<span class="number">888</span></span><br></pre></td></tr></table></figure>

<p>字段：id、name（英雄名称）、win_rate（胜率）、skin_price（皮肤及价格）</p>
<p><strong>实践：</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 先上传文件</span></span><br><span class="line">[eitan@hadoop102 ~]$ hadoop fs -put -p documents/txt/hot_hero_skin_price.txt /user/hive/warehouse/itcast.db/t_hot_hero_skin_price/</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 后建表并指定文件所在位置</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t_hot_hero_skin_price (</span><br><span class="line">    id <span class="type">int</span> comment &quot;ID&quot;,</span><br><span class="line">    name string comment &quot;英雄名称&quot;,</span><br><span class="line">    win_rate <span class="type">int</span> comment &quot;胜率&quot;,</span><br><span class="line">    skin_price map<span class="operator">&lt;</span>string,<span class="type">int</span><span class="operator">&gt;</span> comment &quot;皮肤及价格&quot;</span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED</span><br><span class="line">    FIELDS TERMINATED <span class="keyword">BY</span> &quot;,&quot;            <span class="comment">-- 字段之间分隔符</span></span><br><span class="line">    COLLECTION ITEMS TERMINATED <span class="keyword">BY</span> &quot;-&quot;  <span class="comment">-- 集合元素之间分隔符</span></span><br><span class="line">    MAP KEYS TERMINATED <span class="keyword">BY</span> &quot;:&quot;</span><br><span class="line">LOCATION &quot;/user/hive/warehouse/itcast.db/t_hot_hero_skin_price&quot;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t_hot_hero_skin_price;</span><br></pre></td></tr></table></figure>

<h4 id="Hive内、外部表"><a href="#Hive内、外部表" class="headerlink" title="Hive内、外部表"></a>Hive内、外部表</h4><table>
<thead>
<tr>
<th></th>
<th>内部表</th>
<th>外部表</th>
</tr>
</thead>
<tbody><tr>
<td>创建方式</td>
<td>默认情况</td>
<td>使用EXTERNAL语法关键字</td>
</tr>
<tr>
<td>Hive管理范围</td>
<td>元数据、表数据</td>
<td>元数据</td>
</tr>
<tr>
<td>删除表结果</td>
<td>删除元数据及HDFS上的文件数据</td>
<td>只删除元数据</td>
</tr>
<tr>
<td>操作</td>
<td>支持ARCHIVE，UNARCHIVE，TRUNCATE，MERGE，CONCATENATE</td>
<td>不支持</td>
</tr>
<tr>
<td>事务</td>
<td>支持ACID/事务性</td>
<td>不支持</td>
</tr>
<tr>
<td>缓存</td>
<td>支持结果缓存</td>
<td>不支持</td>
</tr>
</tbody></table>
<h4 id="Hive分区表"><a href="#Hive分区表" class="headerlink" title="Hive分区表"></a>Hive分区表</h4><p><strong>概念：</strong> 分区的概念提供了一种将Hive表数据分离为多个文件/目录的方法。不同分区对应着不同的文件夹，同一分区的数据存储在同一个文件夹下。只需要根据分区值找到对应的文件夹，扫描本分区下的文件即可，避免全表数据扫描。</p>
<h5 id="静态分区"><a href="#静态分区" class="headerlink" title="静态分区"></a>静态分区</h5><p><strong>描述：</strong>静态分区指的是分区的字段值是由用户在加载数据的时候手动指定的。</p>
<p><strong>语法：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA [<span class="keyword">LOCAL</span>] INPATH &quot;&quot; <span class="keyword">INTO</span> <span class="keyword">TABLE</span> table_name <span class="keyword">PARTITION</span> (分区字段 <span class="operator">=</span> <span class="string">&#x27;分区值&#x27;</span>);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[LOCAL] 表示数据是位于本地文件系统还是HDFS文件系统</p>
<p>分区字段不能是表中已经存在的</p>
</blockquote>
<p><strong>案例：</strong></p>
<p>有一组文件位于本地文件系统上，请为其建立分区表。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[eitan@hadoop102 ~]$ cd documents/txt/hero/</span><br><span class="line">[eitan@hadoop102 hero]$ ll</span><br><span class="line">总用量 24</span><br><span class="line">-rw-rw-r--. 1 eitan eitan 480 5月  13 09:48 archer.txt</span><br><span class="line">-rw-rw-r--. 1 eitan eitan 292 5月  13 09:48 assassin.txt</span><br><span class="line">-rw-rw-r--. 1 eitan eitan 883 5月  13 09:48 mage.txt</span><br><span class="line">-rw-rw-r--. 1 eitan eitan 289 5月  13 09:48 support.txt</span><br><span class="line">-rw-rw-r--. 1 eitan eitan 446 5月  13 09:48 tank.txt</span><br><span class="line">-rw-rw-r--. 1 eitan eitan 837 5月  13 09:48 warrior.txt</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 需要把文件同步到hiveserver2所在机器hadoop103上</span></span><br><span class="line">[eitan@hadoop102 ~]$ xsync documents/txt/hero/</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 建表时需要指定分区字段</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t_static_hero_partition (</span><br><span class="line">    id <span class="type">INT</span> COMMENT &quot;ID&quot;,</span><br><span class="line">    name STRING COMMENT &quot;英雄名称&quot;,</span><br><span class="line">    hp_max <span class="type">INT</span> COMMENT &quot;最大生命&quot;,</span><br><span class="line">    mp_max <span class="type">INT</span> COMMENT &quot;最大法力&quot;,</span><br><span class="line">    attack_max <span class="type">INT</span> COMMENT &quot;最高攻击&quot;,</span><br><span class="line">    defense_max <span class="type">INT</span> COMMENT &quot;最大物防&quot;,</span><br><span class="line">    attack_range STRING COMMENT &quot;攻击范围&quot;,</span><br><span class="line">    role_main STRING COMMENT &quot;主要定位&quot;,</span><br><span class="line">    role_assist STRING COMMENT &quot;次要定位&quot;</span><br><span class="line">) COMMENT &quot;王者荣耀英雄信息&quot;</span><br><span class="line">    PARTITIONED <span class="keyword">BY</span> (role STRING)</span><br><span class="line">    <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> &quot;\t&quot;;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 加载本地文件并为其分区</span></span><br><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH &quot;/home/eitan/documents/txt/hero/archer.txt&quot; <span class="keyword">INTO</span> <span class="keyword">TABLE</span> t_static_hero_partition <span class="keyword">PARTITION</span> (role <span class="operator">=</span> &quot;sheshou&quot;);</span><br><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH &quot;/home/eitan/documents/txt/hero/assassin.txt&quot; <span class="keyword">INTO</span> <span class="keyword">TABLE</span> t_static_hero_partition <span class="keyword">PARTITION</span> (role <span class="operator">=</span> &quot;cike&quot;);</span><br><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH &quot;/home/eitan/documents/txt/hero/mage.txt&quot; <span class="keyword">INTO</span> <span class="keyword">TABLE</span> t_static_hero_partition <span class="keyword">PARTITION</span> (role <span class="operator">=</span> &quot;fashi&quot;);</span><br><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH &quot;/home/eitan/documents/txt/hero/support.txt&quot; <span class="keyword">INTO</span> <span class="keyword">TABLE</span> t_static_hero_partition <span class="keyword">PARTITION</span> (role <span class="operator">=</span> &quot;fuzhu&quot;);</span><br><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH &quot;/home/eitan/documents/txt/hero/tank.txt&quot; <span class="keyword">INTO</span> <span class="keyword">TABLE</span> t_static_hero_partition <span class="keyword">PARTITION</span> (role <span class="operator">=</span> &quot;tanke&quot;);</span><br><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH &quot;/home/eitan/documents/txt/hero/warrior.txt&quot; <span class="keyword">INTO</span> <span class="keyword">TABLE</span> t_static_hero_partition <span class="keyword">PARTITION</span> (role <span class="operator">=</span> &quot;zhanshi&quot;);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查询使用分页</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t_static_hero_partition <span class="keyword">WHERE</span> role <span class="operator">=</span> &quot;sheshou&quot;;</span><br></pre></td></tr></table></figure>

<h5 id="动态分区"><a href="#动态分区" class="headerlink" title="动态分区"></a>动态分区</h5><p><strong>描述：</strong>动态分区指的是分区的字段值是基于查询结果自动推断出来的。核心语法就是insert+select。</p>
<blockquote>
<p>启用hive动态分区，需要在hive会话中设置两个参数：</p>
<p>set hive.exec.dynamic.partition=true;</p>
<p>set hive.exec.dynamic.partition.mode=nonstrict;</p>
</blockquote>
<p><strong>语法：</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO TABLE table_name PARTITION (分区字段) SELECT table_fields FROM table_name; </span><br></pre></td></tr></table></figure>

<blockquote>
<p>SELECT 查询字段必须要与 INSERT 后的 table_name 表字段一一对应，并最后加上 PARTITION 的分区字段</p>
</blockquote>
<p><strong>案例：</strong> 对学生表按地区、年龄分区</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建原数据表，并把响应数据放入目标目录下</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t_student</span><br><span class="line">(</span><br><span class="line">    id   <span class="type">int</span> COMMENT &quot;ID&quot;,</span><br><span class="line">    name string COMMENT &quot;学生姓名&quot;,</span><br><span class="line">    sex  string COMMENT &quot;姓名&quot;,</span><br><span class="line">    age  <span class="type">int</span> COMMENT &quot;年龄&quot;,</span><br><span class="line">    area string COMMENT &quot;地区&quot;</span><br><span class="line">) <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> &quot;,&quot;;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建动态分区数据表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t_dynamic_student_partition</span><br><span class="line">(</span><br><span class="line">    id   <span class="type">int</span> COMMENT &quot;ID&quot;,</span><br><span class="line">    name string COMMENT &quot;学生姓名&quot;,</span><br><span class="line">    sex  string COMMENT &quot;姓名&quot;</span><br><span class="line">) PARTITIONED <span class="keyword">BY</span> (area string COMMENT &quot;地区&quot;,age <span class="type">int</span> COMMENT &quot;年龄&quot;)</span><br><span class="line">    <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> &quot;,&quot;;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 通过 INSERT...SELECT 语句插入数据，Hive会启动MAPREDUCE逐行扫描按所定义分区将数据划分到不懂的子目录中</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> t_dynamic_student_partition <span class="keyword">SELECT</span> id, name, sex, area, age <span class="keyword">FROM</span> t_student;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果表中定义了PARTITIONED，则INSERT语句中PARTITION不用写，并且写了分区顺序也是按表定义的来。</p>
</blockquote>
<h4 id="Hive分桶表"><a href="#Hive分桶表" class="headerlink" title="Hive分桶表"></a>Hive分桶表</h4><p><strong>概念：</strong> 将所给数据按规则划分到不同物理文件中。</p>
<p><strong>语法：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--分桶表建表语句</span></span><br><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [db_name.]table_name</span><br><span class="line">[(col_name data_type, ...)]</span><br><span class="line">CLUSTERED <span class="keyword">BY</span> (col_name)</span><br><span class="line"><span class="keyword">INTO</span> N BUCKETS;</span><br></pre></td></tr></table></figure>

<p><strong>案例：</strong></p>
<p>现有美国2021-1-28号，各个县county的新冠疫情累计案例信息，包括确诊病例和死亡病例，数据格式如下所示：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">2021</span>-<span class="number">01</span>-<span class="number">28</span>,Juneau City and Borough,Alaska,<span class="number">02110</span>,<span class="number">1108</span>,<span class="number">3</span></span><br><span class="line"><span class="attribute">2021</span>-<span class="number">01</span>-<span class="number">28</span>,Kenai Peninsula Borough,Alaska,<span class="number">02122</span>,<span class="number">3866</span>,<span class="number">18</span></span><br><span class="line"><span class="attribute">2021</span>-<span class="number">01</span>-<span class="number">28</span>,Ketchikan Gateway Borough,Alaska,<span class="number">02130</span>,<span class="number">272</span>,<span class="number">1</span></span><br><span class="line"><span class="attribute">2021</span>-<span class="number">01</span>-<span class="number">28</span>,Kodiak Island Borough,Alaska,<span class="number">02150</span>,<span class="number">1021</span>,<span class="number">5</span></span><br><span class="line"><span class="attribute">2021</span>-<span class="number">01</span>-<span class="number">28</span>,Kusilvak Census Area,Alaska,<span class="number">02158</span>,<span class="number">1099</span>,<span class="number">3</span></span><br><span class="line"><span class="attribute">2021</span>-<span class="number">01</span>-<span class="number">28</span>,Lake and Peninsula Borough,Alaska,<span class="number">02164</span>,<span class="number">5</span>,<span class="number">0</span></span><br><span class="line"><span class="attribute">2021</span>-<span class="number">01</span>-<span class="number">28</span>,Matanuska-Susitna Borough,Alaska,<span class="number">02170</span>,<span class="number">7406</span>,<span class="number">27</span></span><br><span class="line"><span class="attribute">2021</span>-<span class="number">01</span>-<span class="number">28</span>,Nome Census Area,Alaska,<span class="number">02180</span>,<span class="number">307</span>,<span class="number">0</span></span><br><span class="line"><span class="attribute">2021</span>-<span class="number">01</span>-<span class="number">28</span>,North Slope Borough,Alaska,<span class="number">02185</span>,<span class="number">973</span>,<span class="number">3</span></span><br><span class="line"><span class="attribute">2021</span>-<span class="number">01</span>-<span class="number">28</span>,Northwest Arctic Borough,Alaska,<span class="number">02188</span>,<span class="number">567</span>,<span class="number">1</span></span><br><span class="line"><span class="attribute">2021</span>-<span class="number">01</span>-<span class="number">28</span>,Petersburg Borough,Alaska,<span class="number">02195</span>,<span class="number">43</span>,<span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>字段含义如下：count_date（统计日期）,county（县）,state（州）,fips（县编码code）,cases（累计确诊病例）,deaths（累计死亡病例）。</p>
<p><strong>实践：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--step1:开启分桶的功能 从Hive2.0开始不再需要设置</span></span><br><span class="line"><span class="keyword">set</span> hive.enforce.bucketing<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--step2:创建分桶表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t_usa_covid19_bucket_sort</span><br><span class="line">(</span><br><span class="line">    count_date string COMMENT &quot;统计日期&quot;,</span><br><span class="line">    county     string COMMENT &quot;县&quot;,</span><br><span class="line">    state      string COMMENT &quot;州&quot;,</span><br><span class="line">    fips       <span class="type">int</span> COMMENT &quot;县编码 code&quot;,</span><br><span class="line">    cases      <span class="type">int</span> COMMENT &quot;累计确诊病例&quot;,</span><br><span class="line">    deaths     <span class="type">int</span> COMMENT &quot;累计死亡病例&quot;</span><br><span class="line">)</span><br><span class="line">    <span class="comment">-- 按 state 分组后按 case 降序排序</span></span><br><span class="line">    CLUSTERED <span class="keyword">BY</span> (state) SORTED <span class="keyword">BY</span> (cases <span class="keyword">DESC</span>) <span class="keyword">INTO</span> <span class="number">5</span> BUCKETS</span><br><span class="line">    <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span>;</span><br><span class="line">    </span><br><span class="line"><span class="comment">--step3:创建普通表，并上传数据</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t_usa_covid19</span><br><span class="line">(</span><br><span class="line">    count_date string COMMENT &quot;统计日期&quot;,</span><br><span class="line">    county     string COMMENT &quot;县&quot;,</span><br><span class="line">    state      string COMMENT &quot;州&quot;,</span><br><span class="line">    fips       <span class="type">int</span> COMMENT &quot;县编码 code&quot;,</span><br><span class="line">    cases      <span class="type">int</span> COMMENT &quot;累计确诊病例&quot;,</span><br><span class="line">    deaths     <span class="type">int</span> COMMENT &quot;累计死亡病例&quot;</span><br><span class="line">) <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span>;</span><br><span class="line"></span><br><span class="line">[eitan<span class="variable">@hadoop102</span> <span class="operator">~</span>]$ hadoop fs <span class="operator">-</span>put documents<span class="operator">/</span>txt<span class="operator">/</span>us<span class="operator">-</span>covid19<span class="operator">-</span>counties.dat <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>itcast.db<span class="operator">/</span>t_usa_covid19</span><br><span class="line"></span><br><span class="line"><span class="comment">--step4:使用insert+select语法将数据加载到分桶表中</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t_usa_covid19_bucket_sort <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t_usa_covid19;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>到HDFS上查看t_usa_covid19_bucket底层数据结构可以发现，数据被分为了5个文件</p>
</blockquote>
<h4 id="Hive事务表"><a href="#Hive事务表" class="headerlink" title="Hive事务表"></a>Hive事务表</h4><h5 id="Hive事务表的局限性"><a href="#Hive事务表的局限性" class="headerlink" title="Hive事务表的局限性"></a>Hive事务表的局限性</h5><ul>
<li>尚不支持BEGIN，COMMIT和ROLLBACK。所有语言操作都是自动提交的；</li>
<li>仅支持<strong>ORC文件格式（STORED AS ORC）</strong>；</li>
<li>默认情况下事务配置为关闭。需要<strong>配置参数开启</strong>使用；</li>
<li>表必须是<strong>分桶表（Bucketed）</strong>才可以使用事务功能；</li>
<li>表参数<strong>transactional必须为true</strong>；</li>
<li>外部表不能成为ACID表，不允许从非ACID会话读取/写入ACID表。</li>
</ul>
<h5 id="Hive事务表实践"><a href="#Hive事务表实践" class="headerlink" title="Hive事务表实践"></a>Hive事务表实践</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--Hive中事务表的创建使用</span></span><br><span class="line"><span class="comment">-- 开启事务配置（可以使用set设置当前session生效 也可以配置在hive-site.xml中）</span></span><br><span class="line"><span class="comment">-- 从Hive2.0开始不再需要  是否开启分桶功能</span></span><br><span class="line"><span class="keyword">set</span> hive.enforce.bucketing <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"><span class="comment">-- Hive是否支持并发</span></span><br><span class="line"><span class="keyword">set</span> hive.support.concurrency <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"><span class="comment">-- 动态分区模式  非严格</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode <span class="operator">=</span> nonstrict</span><br><span class="line"><span class="keyword">set</span> hive.txn.manager <span class="operator">=</span> org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;</span><br><span class="line"><span class="comment">--是否在Metastore实例上运行启动线程和清理线程</span></span><br><span class="line"><span class="keyword">set</span> hive.compactor.initiator.on <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"><span class="comment">--在此metastore实例上运行多少个压缩程序工作线程。</span></span><br><span class="line"><span class="keyword">set</span> hive.compactor.worker.threads <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建Hive事务表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> trans_student</span><br><span class="line">(</span><br><span class="line">    id   <span class="type">int</span>,</span><br><span class="line">    name String,</span><br><span class="line">    age  <span class="type">int</span></span><br><span class="line">) CLUSTERED <span class="keyword">BY</span> (id) <span class="keyword">INTO</span> <span class="number">2</span> BUCKETS <span class="comment">-- 按id分桶</span></span><br><span class="line">    STORED <span class="keyword">AS</span> ORC <span class="comment">-- 以ORC文件格式存储</span></span><br><span class="line">    TBLPROPERTIES (<span class="string">&#x27;transactional&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span>);</span><br><span class="line">    </span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> trans_student <span class="keyword">VALUES</span> (<span class="number">1</span>, &quot;allen&quot;, <span class="number">18</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> trans_student;</span><br></pre></td></tr></table></figure>

<h4 id="Hive视图"><a href="#Hive视图" class="headerlink" title="Hive视图"></a>Hive视图</h4><h5 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h5><p>Hive中的视图（view）是一种虚拟表，只保存定义，不实际存储数据。通常从真实的物理表查询中创建生成视图，也可以从已经存在的视图上创建新视图。</p>
<p>创建视图时，将冻结视图的架构，如果删除或更改基础表，则视图将失败，并且视图不能存储数据，操作数据，只能查询。</p>
<p>概况起来就是：视图是用来简化操作的，它其实是一张虚表，在视图中不缓冲记录，也没有提高查询性能。</p>
<h5 id="视图语法"><a href="#视图语法" class="headerlink" title="视图语法"></a>视图语法</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 1、创建视图</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> v_usa_covid19 <span class="keyword">AS</span> <span class="keyword">SELECT</span> count_date, county,state,deaths <span class="keyword">FROM</span> t_usa_covid19 LIMIT <span class="number">5</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> v_usa_covid19_from_view <span class="keyword">AS</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> v_usa_covid19 LIMIT <span class="number">2</span>;</span><br><span class="line"><span class="comment">-- 2、显示当前已有的视图</span></span><br><span class="line"><span class="keyword">SHOW</span> VIEWS;</span><br><span class="line"><span class="comment">-- 3、视图的查询使用</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> v_usa_covid19;</span><br><span class="line"><span class="comment">-- 4、查看视图定义</span></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> v_usa_covid19;</span><br><span class="line"><span class="comment">-- 5、删除视图</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">VIEW</span> v_usa_covid19_from_view;</span><br><span class="line"><span class="comment">-- 6、更改视图属性</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">VIEW</span> v_usa_covid19 <span class="keyword">SET</span> TBLPROPERTIES (&quot;comment&quot; <span class="operator">=</span> &quot;this is a view&quot;);</span><br><span class="line"><span class="comment">-- 7、更改视图定义</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">VIEW</span> v_usa_covid19 <span class="keyword">AS</span> <span class="keyword">SELECT</span> county,deaths <span class="keyword">FROM</span> t_usa_covid19 LIMIT <span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<h4 id="Hive物化视图"><a href="#Hive物化视图" class="headerlink" title="Hive物化视图"></a>Hive物化视图</h4><h5 id="物化视图、视图区别"><a href="#物化视图、视图区别" class="headerlink" title="物化视图、视图区别"></a>物化视图、视图区别</h5><ol>
<li>视图是虚拟的，逻辑存在的，只有定义没有存储数据；</li>
<li>物化视图是真实的，物理存在的，里面存储着预计算的数据；</li>
<li>视图的目的是简化降低查询的复杂度，而物化视图的目的是提高查询性能。</li>
</ol>
<h5 id="物化视图语法"><a href="#物化视图语法" class="headerlink" title="物化视图语法"></a>物化视图语法</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--物化视图的创建语法</span></span><br><span class="line"><span class="keyword">CREATE</span> MATERIALIZED <span class="keyword">VIEW</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name.]materialized_view_name</span><br><span class="line">    [DISABLE REWRITE]</span><br><span class="line">    [COMMENT materialized_view_comment]</span><br><span class="line">    [PARTITIONED <span class="keyword">ON</span> (col_name, ...)]</span><br><span class="line">    [CLUSTERED <span class="keyword">ON</span> (col_name, ...) <span class="operator">|</span> DISTRIBUTED <span class="keyword">ON</span> (col_name, ...) SORTED <span class="keyword">ON</span> (col_name, ...)]</span><br><span class="line">    [</span><br><span class="line">    [<span class="type">ROW</span> FORMAT row_format]</span><br><span class="line">    [STORED <span class="keyword">AS</span> file_format]</span><br><span class="line">    <span class="operator">|</span> STORED <span class="keyword">BY</span> <span class="string">&#x27;storage.handler.class.name&#x27;</span> [<span class="keyword">WITH</span> SERDEPROPERTIES (...)]</span><br><span class="line">  ]</span><br><span class="line">  [LOCATION hdfs_path]</span><br><span class="line">  [TBLPROPERTIES (property_name<span class="operator">=</span>property_value, ...)]</span><br><span class="line"><span class="keyword">AS</span> <span class="keyword">SELECT</span> ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- Drops a materialized view</span></span><br><span class="line"><span class="keyword">DROP</span> MATERIALIZED <span class="keyword">VIEW</span> [db_name.]materialized_view_name;</span><br><span class="line"><span class="comment">-- Shows materialized views (with optional filters)</span></span><br><span class="line"><span class="keyword">SHOW</span> MATERIALIZED VIEWS [<span class="keyword">IN</span> database_name];</span><br><span class="line"><span class="comment">-- Shows information about a specific materialized view</span></span><br><span class="line"><span class="keyword">DESCRIBE</span> [EXTENDED <span class="operator">|</span> FORMATTED] [db_name.]materialized_view_name;</span><br><span class="line"><span class="comment">-- 数据源变更了需要手动执行更新物化视图</span></span><br><span class="line"><span class="keyword">ALTER</span> MATERIALIZED <span class="keyword">VIEW</span> [db_name.]materialized_view_name REBUILD;</span><br></pre></td></tr></table></figure>

<blockquote>
<ol>
<li><p>物化视图创建后，select查询执行数据自动落地，”自动”也即在query的执行期间，任何用户对该物化视图是不可见的；</p>
</li>
<li><p>默认该物化视图可被用于查询优化器optimizer查询重写（在物化视图创建期间可以通过DISABLE REWRITE参数设置禁止使用）；</p>
</li>
<li><p>SerDe和storage format非强制参数，可以用户配置，默认可用hive.materializedview.serde、 hive.materializedview.fileformat；</p>
</li>
<li><p>物化视图可以使用custom storage handlers存储在外部系统（如druid）</p>
</li>
</ol>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CREATE MATERIALIZED VIEW druid_wiki_mv</span><br><span class="line">STORED AS &#x27;org.apache.hadoop.hive.druid.DruidStorageHandler&#x27;</span><br><span class="line">AS SELECT __time, page, user, c_added, c_removed FROM src;</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>物化视图创建后即可用于相关查询的加速，用户提交查询query，若该query经过重写后可命中已建视图，则被重写命中相关已建视图实现查询加速。是否重写查询使用物化视图可以通过全局参数控制（默认为true）：</li>
</ol>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> hive.materializedview.rewriting<span class="operator">=</span><span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

<p>  用户可选择性的失能物化视图的重写：</p>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> MATERIALIZED <span class="keyword">VIEW</span> [db_name.]materialized_view_name ENABLE<span class="operator">|</span>DISABLE REWRITE;</span><br></pre></td></tr></table></figure>
</blockquote>
<h5 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">-- 1、Hive是否支持并发</span><br><span class="line">set hive.support.concurrency = true;</span><br><span class="line">-- 2、设置事务管理器</span><br><span class="line">set hive.txn.manager = org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;</span><br><span class="line">-- 3、创建事务表</span><br><span class="line">CREATE TABLE trans_student</span><br><span class="line">(</span><br><span class="line">    id   int,</span><br><span class="line">    name string,</span><br><span class="line">    area string</span><br><span class="line">) CLUSTERED BY (id) INTO 2 BUCKETS</span><br><span class="line">    STORED AS ORC</span><br><span class="line">    TBLPROPERTIES (&quot;transactional&quot; = &quot;true&quot;);</span><br><span class="line">-- 4、往事务表插入数据</span><br><span class="line">INSERT INTO trans_student SELECT id, name, area FROM t_student;</span><br><span class="line">-- 5、不用物化视图查询聚合结果</span><br><span class="line">SELECT area, count(*) FROM trans_student GROUP BY area;</span><br><span class="line">-- 6、创建物化视图</span><br><span class="line">CREATE MATERIALIZED VIEW m_student_agg AS SELECT age, count(*) FROM trans_student GROUP BY age;</span><br><span class="line">-- 7、再次查询</span><br><span class="line">SELECT area, count(*) FROM trans_student GROUP BY area;</span><br><span class="line">-- 8、失能物化视图</span><br><span class="line">ALTER MATERIALIZED VIEW m_student_agg DISABLE REWRITE;</span><br><span class="line">-- 9、查询执行计划，发现查询的表重物化视图又改回了原事务表</span><br><span class="line">EXPLAIN SELECT area, count(*) FROM trans_student GROUP BY area;</span><br></pre></td></tr></table></figure>

<h4 id="Database（数据库）DDL操作"><a href="#Database（数据库）DDL操作" class="headerlink" title="Database（数据库）DDL操作"></a>Database（数据库）DDL操作</h4><h5 id="Create-Database"><a href="#Create-Database" class="headerlink" title="Create Database"></a>Create Database</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> (DATABASE<span class="operator">|</span>SCHEMA) [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] database_name</span><br><span class="line">[COMMENT database_comment]</span><br><span class="line">[LOCATION hdfs_path]</span><br><span class="line">[<span class="keyword">WITH</span> DBPROPERTIES (property_name<span class="operator">=</span>property_value, ...)];</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>COMMENT</strong>：数据库的注释说明语句</p>
<p><strong>LOCATION</strong>：指定数据库在HDFS存储位置，默认/user/hive/warehouse</p>
<p><strong>WITH DBPROPERTIES</strong>：用于指定一些数据库的属性配置。</p>
</blockquote>
<h5 id="Describe-Database"><a href="#Describe-Database" class="headerlink" title="Describe Database"></a>Describe Database</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DESCRIBE</span> DATABASE<span class="operator">/</span>SCHEMA [EXTENDED] db_name;</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>EXTENDED</strong>：用于显示更多信息。</p>
</blockquote>
<h5 id="Use-Database"><a href="#Use-Database" class="headerlink" title="Use Database"></a>Use Database</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">USE database_name;</span><br></pre></td></tr></table></figure>

<h5 id="Drop-Database"><a href="#Drop-Database" class="headerlink" title="Drop Database"></a>Drop Database</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> (DATABASE<span class="operator">|</span>SCHEMA) [IF <span class="keyword">EXISTS</span>] database_name [RESTRICT<span class="operator">|</span>CASCADE];</span><br></pre></td></tr></table></figure>

<blockquote>
<p>默认行为是<strong>RESTRICT</strong>，这意味着仅在数据库为空时才删除它。要删除带有表的数据库，我们可以使用<strong>CASCADE</strong>。</p>
</blockquote>
<h5 id="Alter-Database"><a href="#Alter-Database" class="headerlink" title="Alter Database"></a>Alter Database</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--更改数据库属性</span></span><br><span class="line"><span class="keyword">ALTER</span> (DATABASE<span class="operator">|</span>SCHEMA) database_name <span class="keyword">SET</span> DBPROPERTIES (property_name<span class="operator">=</span>property_value, ...);</span><br><span class="line"></span><br><span class="line"><span class="comment">--更改数据库所有者</span></span><br><span class="line"><span class="keyword">ALTER</span> (DATABASE<span class="operator">|</span>SCHEMA) database_name <span class="keyword">SET</span> OWNER [<span class="keyword">USER</span><span class="operator">|</span>ROLE] user_or_role;</span><br><span class="line"></span><br><span class="line"><span class="comment">--更改数据库位置</span></span><br><span class="line"><span class="keyword">ALTER</span> (DATABASE<span class="operator">|</span>SCHEMA) database_name <span class="keyword">SET</span> LOCATION hdfs_path;</span><br></pre></td></tr></table></figure>

<h4 id="Table（表）DDL操作"><a href="#Table（表）DDL操作" class="headerlink" title="Table（表）DDL操作"></a>Table（表）DDL操作</h4><h5 id="Describe-Table"><a href="#Describe-Table" class="headerlink" title="Describe Table"></a>Describe Table</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DESCRIBE</span> [FORMATTED<span class="operator">|</span>EXTENDED] [db_name.]table_name;</span><br></pre></td></tr></table></figure>

<h5 id="Drop-Table"><a href="#Drop-Table" class="headerlink" title="Drop Table"></a>Drop Table</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> [IF <span class="keyword">EXISTS</span>] table_name [PURGE]; </span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果已配置垃圾桶（且未指定PURGE），则该表对应的数据实际上将移动到.Trash/Current目录，而元数据完全丢失。如果指定了PURGE，则表数据不会进入.Trash/Current目录，跳过垃圾桶直接被删除。</p>
</blockquote>
<h5 id="Truncate-Table"><a href="#Truncate-Table" class="headerlink" title="Truncate Table"></a>Truncate Table</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">TRUNCATE</span> [<span class="keyword">TABLE</span>] table_name;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>从表中删除所有行。可以简单理解为清空表的所有数据但是保留表的元数据结构。如果HDFS启用了垃圾桶，数据将被丢进垃圾桶，否则将被删除。</p>
</blockquote>
<h5 id="Alter-Table"><a href="#Alter-Table" class="headerlink" title="Alter Table"></a>Alter Table</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 1、更改表名</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name RENAME <span class="keyword">TO</span> new_table_name;</span><br><span class="line"><span class="comment">-- 2、更改表属性</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">SET</span> TBLPROPERTIES (property_name <span class="operator">=</span> property_value, ... );</span><br><span class="line"><span class="comment">-- 3、更改表注释</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> student <span class="keyword">SET</span> TBLPROPERTIES (<span class="string">&#x27;comment&#x27;</span> <span class="operator">=</span> &quot;new comment for student table&quot;);</span><br><span class="line"><span class="comment">-- 4、更改SerDe属性</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">SET</span> SERDE serde_class_name [<span class="keyword">WITH</span> SERDEPROPERTIES (property_name <span class="operator">=</span> property_value, ... )];</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name [<span class="keyword">PARTITION</span> partition_spec] <span class="keyword">SET</span> SERDEPROPERTIES serde_properties;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">SET</span> SERDEPROPERTIES (<span class="string">&#x27;field.delim&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;,&#x27;</span>);</span><br><span class="line"><span class="comment">-- 5、移除SerDe属性</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name [<span class="keyword">PARTITION</span> partition_spec] UNSET SERDEPROPERTIES (property_name, ... );</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 6、更改表的文件存储格式 该操作仅更改表元数据。现有数据的任何转换都必须在Hive之外进行。</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name  <span class="keyword">SET</span> FILEFORMAT file_format;</span><br><span class="line"><span class="comment">-- 7、更改表的存储位置路径</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">SET</span> LOCATION &quot;new location&quot;;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 8、更改列名称/类型/位置/注释</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_change (a <span class="type">int</span>, b <span class="type">int</span>, c <span class="type">int</span>);</span><br><span class="line"><span class="comment">-- First change column a&#x27;s name to a1.</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test_change CHANGE a a1 <span class="type">INT</span>;</span><br><span class="line"><span class="comment">-- Next change column a1&#x27;s name to a2, its data type to string, and put it after column b.</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test_change CHANGE a1 a2 STRING AFTER b;</span><br><span class="line"><span class="comment">-- The new table&#x27;s structure is:  b int, a2 string, c int.</span></span><br><span class="line"><span class="comment">-- Then change column c&#x27;s name to c1, and put it as the first column.</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test_change CHANGE c c1 <span class="type">INT</span> <span class="keyword">FIRST</span>;</span><br><span class="line"><span class="comment">-- The new table&#x27;s structure is:  c1 int, b int, a2 string.</span></span><br><span class="line"><span class="comment">-- Add a comment to column a1</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test_change CHANGE a1 a1 <span class="type">INT</span> COMMENT <span class="string">&#x27;this is column a1&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 9、添加/替换列</span></span><br><span class="line"><span class="comment">-- 使用ADD COLUMNS，您可以将新列添加到现有列的末尾但在分区列之前。</span></span><br><span class="line"><span class="comment">-- REPLACE COLUMNS 将删除所有现有列，并添加新的列集。</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">ADD</span><span class="operator">|</span>REPLACE COLUMNS (col_name data_type,...);</span><br></pre></td></tr></table></figure>

<h4 id="Partition（分区）DDL操作"><a href="#Partition（分区）DDL操作" class="headerlink" title="Partition（分区）DDL操作"></a>Partition（分区）DDL操作</h4><h5 id="Add-Partition"><a href="#Add-Partition" class="headerlink" title="Add Partition"></a>Add Partition</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 一次添加一个分区</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">ADD</span> <span class="keyword">PARTITION</span> (dt<span class="operator">=</span><span class="string">&#x27;20170101&#x27;</span>) location <span class="string">&#x27;/user/hadoop/warehouse/table_name/dt=20170101&#x27;</span>; </span><br><span class="line"></span><br><span class="line"><span class="comment">-- 一次添加多个分区</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">ADD</span> <span class="keyword">PARTITION</span> (dt<span class="operator">=</span><span class="string">&#x27;2008-08-08&#x27;</span>, country<span class="operator">=</span><span class="string">&#x27;us&#x27;</span>) location <span class="string">&#x27;/path/to/us/part080808&#x27;</span></span><br><span class="line"><span class="keyword">PARTITION</span> (dt<span class="operator">=</span><span class="string">&#x27;2008-08-09&#x27;</span>, country<span class="operator">=</span><span class="string">&#x27;us&#x27;</span>) location <span class="string">&#x27;/path/to/us/part080809&#x27;</span>;  </span><br></pre></td></tr></table></figure>

<blockquote>
<p>分区值仅在为字符串时才应加引号。位置必须是数据文件所在的目录。</p>
<p>ADD PARTITION会更改表元数据，但不会加载数据。如果分区位置中不存在数据，查询将不会返回任何结果。</p>
</blockquote>
<h5 id="Rename-Partition"><a href="#Rename-Partition" class="headerlink" title="Rename Partition"></a>Rename Partition</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 重命名分区</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">PARTITION</span> partition_spec RENAME <span class="keyword">TO</span> <span class="keyword">PARTITION</span> partition_spec;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">PARTITION</span> (dt<span class="operator">=</span><span class="string">&#x27;2008-08-09&#x27;</span>) RENAME <span class="keyword">TO</span> <span class="keyword">PARTITION</span> (dt<span class="operator">=</span><span class="string">&#x27;20080809&#x27;</span>);</span><br></pre></td></tr></table></figure>

<h5 id="Delete-Partition"><a href="#Delete-Partition" class="headerlink" title="Delete Partition"></a>Delete Partition</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">DROP</span> [IF <span class="keyword">EXISTS</span>] <span class="keyword">PARTITION</span> (dt<span class="operator">=</span><span class="string">&#x27;2008-08-08&#x27;</span>, country<span class="operator">=</span><span class="string">&#x27;us&#x27;</span>);</span><br><span class="line"><span class="comment">-- 直接删除数据 不进垃圾桶</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">DROP</span> [IF <span class="keyword">EXISTS</span>] <span class="keyword">PARTITION</span> (dt<span class="operator">=</span><span class="string">&#x27;2008-08-08&#x27;</span>, country<span class="operator">=</span><span class="string">&#x27;us&#x27;</span>) PURGE;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>将删除该分区的数据和元数据。</p>
</blockquote>
<h5 id="Msck-Partition"><a href="#Msck-Partition" class="headerlink" title="Msck Partition"></a>Msck Partition</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 修复分区</span></span><br><span class="line">MSCK [REPAIR] <span class="keyword">TABLE</span> table_name [<span class="keyword">ADD</span><span class="operator">/</span><span class="keyword">DROP</span><span class="operator">/</span>SYNC PARTITIONS];</span><br></pre></td></tr></table></figure>

<blockquote>
<p>MSCK命令的默认选项是“添加分区”。使用此选项，它将把HDFS上存在但元存储中不存在的所有分区添加到元存储中。DROP PARTITIONS选项将从已经从HDFS中删除的metastore中删除分区信息。SYNC PARTITIONS选项等效于调用ADD和DROP PARTITIONS。</p>
<p>如果存在大量未跟踪的分区，则可以批量运行MSCK REPAIR TABLE，以避免OOME（内存不足错误）。</p>
</blockquote>
<h5 id="Alter-Partition"><a href="#Alter-Partition" class="headerlink" title="Alter Partition"></a>Alter Partition</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 更改分区文件存储格式</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">PARTITION</span> (dt<span class="operator">=</span><span class="string">&#x27;2008-08-09&#x27;</span>) <span class="keyword">SET</span> FILEFORMAT file_format;</span><br><span class="line"><span class="comment">-- 更改分区位置</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">PARTITION</span> (dt<span class="operator">=</span><span class="string">&#x27;2008-08-09&#x27;</span>) <span class="keyword">SET</span> LOCATION &quot;new location&quot;;</span><br></pre></td></tr></table></figure>

<h4 id="Hive-Show显示语法"><a href="#Hive-Show显示语法" class="headerlink" title="Hive Show显示语法"></a>Hive Show显示语法</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 1、显示所有数据库 SCHEMAS和DATABASES的用法 功能一样</span></span><br><span class="line"><span class="keyword">SHOW</span> DATABASES<span class="operator">|</span>SCHEMAS;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 2、显示当前数据库所有表/视图/物化视图/分区/索引</span></span><br><span class="line"><span class="keyword">SHOW</span> TABLES [<span class="keyword">IN</span> database_name]; <span class="comment">--指定某个数据库</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 3、显示当前数据库下所有视图</span></span><br><span class="line"><span class="keyword">SHOW</span> VIEWS;</span><br><span class="line"><span class="comment">-- show all views that start with &quot;test_&quot;</span></span><br><span class="line"><span class="keyword">SHOW</span> VIEWS <span class="string">&#x27;test_*&#x27;</span>;</span><br><span class="line"><span class="comment">-- show views from database database_name</span></span><br><span class="line"><span class="keyword">SHOW</span> VIEWS [<span class="keyword">IN</span><span class="operator">/</span><span class="keyword">FROM</span> database_name];</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 4、显示当前数据库下所有物化视图</span></span><br><span class="line"><span class="keyword">SHOW</span> MATERIALIZED VIEWS [<span class="keyword">IN</span><span class="operator">/</span><span class="keyword">FROM</span> database_name];</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 5、显示表分区信息，分区按字母顺序列出，不是分区表执行该语句会报错</span></span><br><span class="line"><span class="keyword">SHOW</span> PARTITIONS table_name;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 6、显示表/分区的扩展信息</span></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">TABLE</span> EXTENDED [<span class="keyword">IN</span><span class="operator">|</span><span class="keyword">FROM</span> database_name] <span class="keyword">LIKE</span> table_name;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 7、显示表的属性信息</span></span><br><span class="line"><span class="keyword">SHOW</span> TBLPROPERTIES table_name;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 8、显示表、视图的创建语句</span></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> ([db_name.]table_name<span class="operator">|</span>view_name);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 9、显示表中的所有列，包括分区列。</span></span><br><span class="line"><span class="keyword">SHOW</span> COLUMNS (<span class="keyword">FROM</span><span class="operator">|</span><span class="keyword">IN</span>) table_name [(<span class="keyword">FROM</span><span class="operator">|</span><span class="keyword">IN</span>) db_name];</span><br><span class="line"></span><br><span class="line"><span class="comment">--10、显示当前支持的所有自定义和内置的函数</span></span><br><span class="line"><span class="keyword">SHOW</span> FUNCTIONS;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 11、Describe desc</span></span><br><span class="line"><span class="comment">-- 查看表信息</span></span><br><span class="line"><span class="keyword">DESC</span> EXTENDED table_name;</span><br><span class="line"><span class="comment">-- 查看表信息（格式化美观）</span></span><br><span class="line"><span class="keyword">DESC</span> FORMATTED table_name;</span><br><span class="line"><span class="comment">-- 查看数据库相关信息</span></span><br><span class="line"><span class="keyword">DESC</span> DATABASE database_name;</span><br></pre></td></tr></table></figure>

<h3 id="Hive-的数据操纵语言（DML）"><a href="#Hive-的数据操纵语言（DML）" class="headerlink" title="Hive 的数据操纵语言（DML）"></a>Hive 的数据操纵语言（DML）</h3><h4 id="DML-LOAD加载数据"><a href="#DML-LOAD加载数据" class="headerlink" title="DML-LOAD加载数据"></a>DML-LOAD加载数据</h4><h5 id="LOAD语法"><a href="#LOAD语法" class="headerlink" title="LOAD语法"></a>LOAD语法</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA [<span class="keyword">LOCAL</span>] INPATH <span class="string">&#x27;filepath&#x27;</span> [OVERWRITE] <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)]</span><br><span class="line"></span><br><span class="line">LOAD DATA [<span class="keyword">LOCAL</span>] INPATH <span class="string">&#x27;filepath&#x27;</span> [OVERWRITE] <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)] [INPUTFORMAT <span class="string">&#x27;inputformat&#x27;</span> SERDE <span class="string">&#x27;serde&#x27;</span>] (<span class="number">3.0</span> <span class="keyword">or</span> later)</span><br></pre></td></tr></table></figure>

<ol>
<li><p><strong>filepath</strong></p>
<p>filepath表示的待移动数据的路径，可以引用一个文件（在这种情况下，Hive将文件移动到表中），也可以是一个目录（在这种情况下，Hive将把该目录中的所有文件移动到表中）。</p>
<p>具有schema的完整URI，例如：hdfs://namenode:9000/user/hive/project/data1</p>
</li>
<li><p><strong>LOCAL</strong></p>
<p>如果指定了LOCAL， load命令将在本地文件系统中查找文件路径。</p>
<p>如果没有指定LOCAL关键字，如果filepath指向的是一个完整的URI，hive会直接使用这个URI。否则Hive会使用hadoop配置文件中定义的schema 和 authority，即参数fs.default.name指定的（默认HDFS）。</p>
</li>
<li><p><strong>OVERWRITE</strong></p>
<p>如果使用了OVERWRITE关键字，则目标表（或者分区）中的内容会被删除，然后再将 filepath 指向的文件/目录中的内容添加到表/分区中。</p>
</li>
</ol>
<h5 id="案例-1"><a href="#案例-1" class="headerlink" title="案例"></a>案例</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- step1:建表</span></span><br><span class="line"><span class="comment">-- 建表 student_local 用于演示从本地加载数据</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_local</span><br><span class="line">(</span><br><span class="line">    num  <span class="type">int</span>,</span><br><span class="line">    name string,</span><br><span class="line">    sex  string,</span><br><span class="line">    age  <span class="type">int</span>,</span><br><span class="line">    dept string</span><br><span class="line">) <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span>;</span><br><span class="line"><span class="comment">-- 建表 student_hdfs  用于演示从HDFS加载数据</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_hdfs</span><br><span class="line">(</span><br><span class="line">    num  <span class="type">int</span>,</span><br><span class="line">    name string,</span><br><span class="line">    sex  string,</span><br><span class="line">    age  <span class="type">int</span>,</span><br><span class="line">    dept string</span><br><span class="line">) <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span>;</span><br><span class="line"><span class="comment">-- 建表 student_hdfs_p 用于演示从HDFS加载数据到分区表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_hdfs_p</span><br><span class="line">(</span><br><span class="line">    num  <span class="type">int</span>,</span><br><span class="line">    name string,</span><br><span class="line">    sex  string,</span><br><span class="line">    age  <span class="type">int</span>,</span><br><span class="line">    dept string</span><br><span class="line">) PARTITIONED <span class="keyword">BY</span> (country string)</span><br><span class="line">    <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span>;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment">-- step2:加载数据</span></span><br><span class="line"><span class="comment">-- 从本地加载数据  数据位于HS2本地文件系统  本质是hadoop fs -put上传操作</span></span><br><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH &quot;/home/eitan/documents/txt/students.txt&quot; <span class="keyword">INTO</span> <span class="keyword">TABLE</span> student_local;</span><br><span class="line"><span class="comment">-- 从HDFS加载数据  数据位于HDFS文件系统根目录下  本质是hadoop fs -mv 移动操作</span></span><br><span class="line">LOAD DATA INPATH &quot;/students.txt&quot; <span class="keyword">INTO</span> <span class="keyword">TABLE</span> student_hdfs;</span><br><span class="line"><span class="comment">-- 从HDFS加载数据到分区表中并制定分区  数据位于HDFS文件系统根目录下</span></span><br><span class="line">LOAD DATA INPATH &quot;/students.txt&quot; <span class="keyword">INTO</span> <span class="keyword">TABLE</span> student_hdfs_p <span class="keyword">PARTITION</span> (country <span class="operator">=</span> &quot;China&quot;);</span><br></pre></td></tr></table></figure>

<h5 id="Hive3-0-Load新特性"><a href="#Hive3-0-Load新特性" class="headerlink" title="Hive3.0 Load新特性"></a>Hive3.0 Load新特性</h5><p>Hive 3.0及更高版本中，除了移动复制操作之外，还支持其他加载操作，因为Hive在内部在某些场合下会将加载重写为INSERT AS SELECT。</p>
<p>比如，如果表具有分区，则load命令没有指定分区，则将load转换为INSERT AS SELECT，并假定最后一组列为分区列。如果文件不符合预期的架构，它将引发错误。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">------- hive 3.0 load命令新特性 ------------------</span></span><br><span class="line"><span class="comment">-- tab1.txt内容如下</span></span><br><span class="line"><span class="number">11</span>,<span class="number">22</span>,<span class="number">1</span></span><br><span class="line"><span class="number">33</span>,<span class="number">44</span>,<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> tab1</span><br><span class="line">(</span><br><span class="line">    col1 <span class="type">int</span>,</span><br><span class="line">    col2 <span class="type">int</span></span><br><span class="line">) PARTITIONED <span class="keyword">BY</span> (col3 <span class="type">int</span>)</span><br><span class="line">    <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 加载数据</span></span><br><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH &quot;/home/eitan/documents/txt/tab1.txt&quot; <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tab1;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>本来加载的时候没有指定分区，语句是报错的，但是文件的格式符合表的结构，前两个是col1,col2,最后一个是分区字段col3，则此时会将load语句转换成为insert as select语句。</p>
</blockquote>
<h4 id="DML-Insert插入数据"><a href="#DML-Insert插入数据" class="headerlink" title="DML-Insert插入数据"></a>DML-Insert插入数据</h4><h5 id="insert-select"><a href="#insert-select" class="headerlink" title="insert + select"></a>insert + select</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- Hive中insert主要是结合select查询语句使用，将查询结果插入到表中，例如：</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...) [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>]] select_statement1 <span class="keyword">FROM</span> from_statement;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)] select_statement1 <span class="keyword">FROM</span> from_statement;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>INSERT OVERWRITE将覆盖表或分区中的任何现有数据。</p>
<p>如果查询出来的数据类型和插入表格对应的列数据类型不一致，将会进行转换，但是不能保证转换一定成功，转换失败的数据将会为NULL。</p>
</blockquote>
<h5 id="multiple-inserts多重插入"><a href="#multiple-inserts多重插入" class="headerlink" title="multiple inserts多重插入"></a>multiple inserts多重插入</h5><p>multiple inserts可以翻译成为多次插入，多重插入，核心是：一次扫描，多次插入。其功能也体现出来了就是减少扫描的次数。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">------------ multiple inserts ----------------------</span></span><br><span class="line"><span class="comment">-- 当前库下已有一张表student</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student;</span><br><span class="line"><span class="comment">-- 创建两张新表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> student_insert1(sno <span class="type">int</span>);</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> student_insert2(sname string);</span><br><span class="line"><span class="comment">-- 多重插入</span></span><br><span class="line"><span class="keyword">FROM</span> t_student</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> student_insert1 <span class="keyword">SELECT</span> id</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> student_insert2 <span class="keyword">SELECT</span> name;</span><br></pre></td></tr></table></figure>

<h5 id="dynamic-partition-insert动态分区插入"><a href="#dynamic-partition-insert动态分区插入" class="headerlink" title="dynamic partition insert动态分区插入"></a>dynamic partition insert动态分区插入</h5><p>分区的值是由后续的select查询语句的结果来动态确定的。根据查询结果自动分区。案例参照 <strong>分区表-动态分区</strong></p>
<h5 id="insert-directory导出数据"><a href="#insert-directory导出数据" class="headerlink" title="insert + directory导出数据"></a>insert + directory导出数据</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 标准语法:</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE [<span class="keyword">LOCAL</span>] DIRECTORY directory1</span><br><span class="line">    [<span class="type">ROW</span> FORMAT row_format] [STORED <span class="keyword">AS</span> file_format]</span><br><span class="line"><span class="keyword">SELECT</span> ... <span class="keyword">FROM</span> ...</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 多重导出 Hive extension (multiple inserts):</span></span><br><span class="line"><span class="keyword">FROM</span> from_statement</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE [<span class="keyword">LOCAL</span>] DIRECTORY directory1 select_statement1</span><br><span class="line">[<span class="keyword">INSERT</span> OVERWRITE [<span class="keyword">LOCAL</span>] DIRECTORY directory2 select_statement2] ...</span><br></pre></td></tr></table></figure>

<blockquote>
<p>导出操作是一个OVERWRITE覆盖操作。</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--1、导出查询结果到HDFS指定目录下</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE DIRECTORY <span class="string">&#x27;/tmp/hive_export/e1&#x27;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t_student;</span><br><span class="line"></span><br><span class="line"><span class="comment">--2、导出时指定分隔符和文件存储格式</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE DIRECTORY <span class="string">&#x27;/tmp/hive_export/e2&#x27;</span> <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t_student;</span><br><span class="line"></span><br><span class="line"><span class="comment">--3、导出数据到本地文件系统指定目录下</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">LOCAL</span> DIRECTORY <span class="string">&#x27;/home/eitan/hive_export/e1&#x27;</span> STORED <span class="keyword">AS</span> ORC <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t_student;</span><br></pre></td></tr></table></figure>

<h4 id="Hive-Transaction事务"><a href="#Hive-Transaction事务" class="headerlink" title="Hive Transaction事务"></a>Hive Transaction事务</h4><h5 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h5><ol>
<li><p>用HDFS文件作为原始数据（基础数据），用delta保存事务操作的记录增量数据；</p>
</li>
<li><p>正在执行中的事务，是以一个staging开头的文件夹维护的，执行结束就是delta文件夹。每次执行一次事务操作都会有这样的一个delta增量文件夹;</p>
</li>
<li><p>当访问Hive数据时，根据HDFS原始文件和delta增量文件做合并，查询最新的数据。</p>
</li>
</ol>
<h5 id="合并器-Compactor"><a href="#合并器-Compactor" class="headerlink" title="合并器(Compactor)"></a><strong>合并器(Compactor)</strong></h5><ol>
<li><p>随着表的修改操作，创建了越来越多的delta增量文件，就需要合并以保持足够的性能。</p>
</li>
<li><p>合并器Compactor是一套在Hive Metastore内运行，支持ACID系统的后台进程。所有合并都是在后台完成的，不会阻止数据的并发读、写。合并后，系统将等待所有旧文件的读操作完成后，删除旧文件。</p>
</li>
<li><p>合并操作分为两种，minor compaction（小合并）、major compaction（大合并）：</p>
<ol>
<li><p>小合并会将一组delta增量文件重写为单个增量文件，默认触发条件为10个delta文件；</p>
</li>
<li><p>大合并将一个或多个增量文件和基础文件重写为新的基础文件，默认触发条件为delta文件相应于基础文件占比，10%。</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>hive.compactor.delta.num.threshold</td>
<td>Specifies the number of delta directories in a partition that triggers an automatic minor compaction.The default value is 10.</td>
</tr>
<tr>
<td>hive.compactor.delta.pct.threshold</td>
<td>Specifies the percentage size of delta files relative to the corresponding base files that triggers an automatic major compaction. The default value is. 1, which is 10 percent.</td>
</tr>
</tbody></table>
</li>
</ol>
</li>
</ol>
<h4 id="DML-Update、Delete更新、删除数据"><a href="#DML-Update、Delete更新、删除数据" class="headerlink" title="DML-Update、Delete更新、删除数据"></a>DML-Update、Delete更新、删除数据</h4><p>见<strong>Hive事务表-Hive事务表实践</strong></p>
<h3 id="Hive-的数据查询语言（DQL）"><a href="#Hive-的数据查询语言（DQL）" class="headerlink" title="Hive 的数据查询语言（DQL）"></a>Hive 的数据查询语言（DQL）</h3><h5 id="语法树"><a href="#语法树" class="headerlink" title="语法树"></a>语法树</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[<span class="keyword">WITH</span> CommonTableExpression (, CommonTableExpression)<span class="operator">*</span>] </span><br><span class="line"><span class="keyword">SELECT</span> [<span class="keyword">ALL</span> <span class="operator">|</span> <span class="keyword">DISTINCT</span>] select_expr, select_expr, ...</span><br><span class="line">  <span class="keyword">FROM</span> table_reference</span><br><span class="line">  [<span class="keyword">WHERE</span> where_condition]</span><br><span class="line">  [<span class="keyword">GROUP</span> <span class="keyword">BY</span> col_list]</span><br><span class="line">  [<span class="keyword">ORDER</span> <span class="keyword">BY</span> col_list]</span><br><span class="line">  [CLUSTER <span class="keyword">BY</span> col_list</span><br><span class="line">    <span class="operator">|</span> [DISTRIBUTE <span class="keyword">BY</span> col_list] [SORT <span class="keyword">BY</span> col_list]</span><br><span class="line">  ]</span><br><span class="line"> [LIMIT [<span class="keyword">offset</span>,] <span class="keyword">rows</span>]</span><br></pre></td></tr></table></figure>

<blockquote>
<ul>
<li>ALL和DISTINCT选项指定是否应返回重复的行。如果没有给出这些选项，则默认值为ALL（返回所有匹配的行）。DISTINCT指定从结果集中删除重复的行。</li>
</ul>
</blockquote>
<h5 id="执行顺序"><a href="#执行顺序" class="headerlink" title="执行顺序"></a>执行顺序</h5><p>在查询过程中执行顺序：<strong>from &gt; where &gt; group（含聚合）&gt; having &gt;order &gt; select；</strong></p>
<ol>
<li><p>聚合语句(sum,min,max,avg,count)要比having子句优先执行</p>
</li>
<li><p>where子句在查询过程中执行优先级别优先于聚合语句(sum,min,max,avg,count)</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> state,<span class="built_in">sum</span>(deaths) <span class="keyword">as</span> cnts</span><br><span class="line"><span class="keyword">from</span> t_usa_covid19_p</span><br><span class="line"><span class="keyword">where</span> count_date <span class="operator">=</span> &quot;2021-01-28&quot;</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> state</span><br><span class="line"><span class="keyword">having</span> cnts<span class="operator">&gt;</span> <span class="number">10000</span>;</span><br></pre></td></tr></table></figure>

<h5 id="ORDER-BY"><a href="#ORDER-BY" class="headerlink" title="ORDER BY"></a>ORDER BY</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">---order by</span></span><br><span class="line"><span class="comment">--根据字段进行排序</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_usa_covid19_p</span><br><span class="line"><span class="keyword">where</span> count_date <span class="operator">=</span> &quot;2021-01-28&quot;</span><br><span class="line"><span class="keyword">and</span> state <span class="operator">=</span>&quot;California&quot;</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> deaths; <span class="comment">--默认asc null first</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_usa_covid19_p</span><br><span class="line"><span class="keyword">where</span> count_date <span class="operator">=</span> &quot;2021-01-28&quot;</span><br><span class="line"><span class="keyword">and</span> state <span class="operator">=</span>&quot;California&quot;</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> deaths <span class="keyword">desc</span>; <span class="comment">--指定desc null last</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--强烈建议将LIMIT与ORDER BY一起使用。避免数据集行数过大</span></span><br><span class="line"><span class="comment">--当hive.mapred.mode设置为strict严格模式时，使用不带LIMIT的ORDER BY时会引发异常。</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_usa_covid19_p</span><br><span class="line"><span class="keyword">where</span> count_date <span class="operator">=</span> &quot;2021-01-28&quot;</span><br><span class="line">  <span class="keyword">and</span> state <span class="operator">=</span>&quot;California&quot;</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> deaths <span class="keyword">desc</span></span><br><span class="line">limit <span class="number">3</span>;</span><br></pre></td></tr></table></figure>

<h5 id="CLUSTER-BY"><a href="#CLUSTER-BY" class="headerlink" title="CLUSTER BY"></a>CLUSTER BY</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--cluster by</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student;</span><br><span class="line"><span class="comment">--不指定reduce task个数</span></span><br><span class="line"><span class="comment">--日志显示：Number of reduce tasks not specified. Estimated from input data size: 1</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student cluster <span class="keyword">by</span> sno;</span><br><span class="line"></span><br><span class="line"><span class="comment">--手动设置reduce task个数</span></span><br><span class="line"><span class="keyword">set</span> mapreduce.job.reduces <span class="operator">=</span><span class="number">2</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student cluster <span class="keyword">by</span> sno;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Hive SQL中的<strong>CLUSTER BY</strong>语法可以指定根据后面的字段将数据分组，每组内再根据这个字段正序排序（不允许指定排序规则），概况起来就是：<strong>根据同一个字段，分且排序</strong>。</p>
</blockquote>
<h5 id="DISTRIBUTE-BY-SORT-BY"><a href="#DISTRIBUTE-BY-SORT-BY" class="headerlink" title="DISTRIBUTE BY +SORT BY"></a>DISTRIBUTE BY +SORT BY</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 案例：把学生表数据根据性别分为两个部分，每个分组内根据年龄的倒序排序。</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student distribute <span class="keyword">by</span> sex sort <span class="keyword">by</span> sage <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果说CLUSTER BY的功能是分且排序（同一个字段），那么DISTRIBUTE BY +SORT BY就相当于把cluster by的功能一分为二：<strong>DISTRIBUTE BY负责分，SORT BY负责分组内排序</strong>，并且可以是不同的字段。</p>
<p>sort by不是全局排序，其在数据进入reducer前完成排序。因此，如果用sort by进行排序，并且设置mapred.reduce.tasks&gt;1，则sort by只保证每个reducer的输出有序，不保证全局有序。</p>
<p>distribute by(字段)根据指定字段将数据分到不同的reducer，分发算法是hash散列。</p>
</blockquote>
<h5 id="Union联合查询"><a href="#Union联合查询" class="headerlink" title="Union联合查询"></a>Union联合查询</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select_statement <span class="keyword">UNION</span> [<span class="keyword">ALL</span> <span class="operator">|</span> <span class="keyword">DISTINCT</span>] select_statement <span class="keyword">UNION</span> [<span class="keyword">ALL</span> <span class="operator">|</span> <span class="keyword">DISTINCT</span>] select_statement ...</span><br></pre></td></tr></table></figure>

<h5 id="Common-Table-Expressions（CTE）"><a href="#Common-Table-Expressions（CTE）" class="headerlink" title="Common Table Expressions（CTE）"></a>Common Table Expressions（CTE）</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--选择语句中的CTE</span></span><br><span class="line"><span class="keyword">with</span> q1 <span class="keyword">as</span> (<span class="keyword">select</span> sno,sname,sage <span class="keyword">from</span> student <span class="keyword">where</span> sno <span class="operator">=</span> <span class="number">95002</span>)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> q1;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>公用表表达式（CTE）是一个临时结果集，该结果集是从WITH子句中指定的简单查询派生而来的，该查询紧接在SELECT或INSERT关键字之前。</p>
</blockquote>
<h5 id="join连接查询"><a href="#join连接查询" class="headerlink" title="join连接查询"></a>join连接查询</h5><ol>
<li><p>inner join</p>
<p>连接的两个表中都存在与连接条件相匹配的数据才会被留下来。</p>
</li>
<li><p>left join</p>
<p>join时以左表的全部数据为准，右边与之关联；左表数据全部返回，右表关联上的显示返回，关联不上的显示null返回。</p>
</li>
<li><p>right jion</p>
<p>join时以右表的全部数据为准，左边与之关联；右表数据全部返回，左表关联上的显示返回，关联不上的显示null返回。</p>
</li>
<li><p>full outer join</p>
<p>它等价于对这两个数据集合分别进行左外连接和右外连接，然后再使用消去重复行的操作将上述两个结果集合并为一个结果集。</p>
<p><img src="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220513231016.png" alt="image-20220513231011099"></p>
</li>
<li><p>left semi join</p>
<p>只返回左边表的记录的字段，前提是其记录对于右边的表满足ON语句中的判定条件。相当于inner join但是只返回左边的字段。</p>
</li>
<li><p>cross join</p>
<p>相当于无条件的inner join。</p>
</li>
<li><p>join注意事项</p>
<ul>
<li><p>如果每个表在联接子句中使用相同的列，则Hive将多个表上的联接转换为单个MR作业</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.val, b.val, c.val <span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.key <span class="operator">=</span> b.key1) <span class="keyword">JOIN</span> c <span class="keyword">ON</span> (c.key <span class="operator">=</span> b.key1)</span><br><span class="line"><span class="comment">--由于联接中仅涉及b的key1列，因此被转换为1个MR作业来执行，并且表a和b的键的特定值的值被缓冲在reducer的内存中。然后，对于从c中检索的每一行，将使用缓冲的行来计算联接。</span></span><br><span class="line"><span class="keyword">SELECT</span> a.val, b.val, c.val <span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.key <span class="operator">=</span> b.key1) <span class="keyword">JOIN</span> c <span class="keyword">ON</span> (c.key <span class="operator">=</span> b.key2)</span><br><span class="line"><span class="comment">--计算涉及两个MR作业。其中的第一个将a与b连接起来，并缓冲a的值，同时在reducer中流式传输b的值。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>在join的时候，可以通过语法STREAMTABLE提示指定要流式传输的表。如果省略STREAMTABLE提示，则Hive将流式传输最右边的表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="comment">/*+ STREAMTABLE(a) */</span> a.val, b.val, c.val <span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.key <span class="operator">=</span> b.key1) <span class="keyword">JOIN</span> c <span class="keyword">ON</span> (c.key <span class="operator">=</span> b.key1)</span><br><span class="line"><span class="comment">--a,b,c三个表都在一个MR作业中联接，并且表b和c的键的特定值的值被缓冲在reducer的内存中。然后，对于从a中检索到的每一行，将使用缓冲的行来计算联接。如果省略STREAMTABLE提示，则Hive将流式传输最右边的表。</span></span><br></pre></td></tr></table></figure></li>
<li><p> 如果除一个要连接的表之外的所有表都很小，则可以将其作为仅map作业执行</p>
</li>
</ul>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="comment">/*+ MAPJOIN(b) */</span> a.key, a.value <span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">ON</span> a.key <span class="operator">=</span> b.key</span><br><span class="line"><span class="comment">--不需要reducer。对于A的每个Mapper，B都会被完全读取。限制是不能执行FULL / RIGHT OUTER JOIN b。</span></span><br></pre></td></tr></table></figure></li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>Eitan
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="http://example.com/2022/05/11/Hadoop%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AHive/" title="Hadoop（三）：Hive">http://example.com/2022/05/11/Hadoop（三）：Hive/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/hadoop/" rel="tag"><i class="fa fa-tag"></i> hadoop</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/05/09/Hadoop%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9AHDFS/" rel="prev" title="Hadoop（二）：HDFS">
                  <i class="fa fa-chevron-left"></i> Hadoop（二）：HDFS
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/05/20/Spark%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" rel="next" title="Spark（一）：环境搭建">
                  Spark（一）：环境搭建 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>





<script src="/js/comments.js"></script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Eitan</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="/js/third-party/search/local-search.js"></script>






  





</body>
</html>
