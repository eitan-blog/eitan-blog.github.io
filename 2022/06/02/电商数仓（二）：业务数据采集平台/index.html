<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;example.com&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Muse&quot;,&quot;version&quot;:&quot;8.4.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;right&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:true,&quot;bookmark&quot;:{&quot;enable&quot;:true,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:true,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;},&quot;path&quot;:&quot;&#x2F;search.xml&quot;,&quot;localsearch&quot;:{&quot;enable&quot;:true,&quot;trigger&quot;:&quot;auto&quot;,&quot;top_n_per_article&quot;:1,&quot;unescape&quot;:false,&quot;preload&quot;:false}}</script>
<meta name="description" content="本文为学习笔记，对应视频教程来自【尚硅谷】电商数仓V5.0 电商业务数据模拟生成业务数据MySQL安装参考Hadoop（三）：Hive 业务数据生成通过脚本建表生成业务数据12345678910# 1.在hadoop102的&#x2F;opt&#x2F;module&#x2F;目录下创建db_log文件夹[eitan@hadoop102 ~]$ mkdir &#x2F;opt&#x2F;module&#x2F;db_log# 2.把gmall2020-mo">
<meta property="og:type" content="article">
<meta property="og:title" content="电商数仓（二）：业务数据采集平台">
<meta property="og:url" content="http://example.com/2022/06/02/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B0/index.html">
<meta property="og:site_name" content="Eitan&#39;s Blog">
<meta property="og:description" content="本文为学习笔记，对应视频教程来自【尚硅谷】电商数仓V5.0 电商业务数据模拟生成业务数据MySQL安装参考Hadoop（三）：Hive 业务数据生成通过脚本建表生成业务数据12345678910# 1.在hadoop102的&#x2F;opt&#x2F;module&#x2F;目录下创建db_log文件夹[eitan@hadoop102 ~]$ mkdir &#x2F;opt&#x2F;module&#x2F;db_log# 2.把gmall2020-mo">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220603122316.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220604151701.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220605145305.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220605153029.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220605180311.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220606110929.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220606163057.png">
<meta property="article:published_time" content="2022-06-02T12:16:41.859Z">
<meta property="article:modified_time" content="2022-06-06T08:31:08.153Z">
<meta property="article:author" content="Eitan">
<meta property="article:tag" content="Project">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220603122316.png">


<link rel="canonical" href="http://example.com/2022/06/02/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B0/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:false,&quot;isPost&quot;:true,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:true,&quot;permalink&quot;:&quot;http:&#x2F;&#x2F;example.com&#x2F;2022&#x2F;06&#x2F;02&#x2F;%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B0&#x2F;&quot;,&quot;path&quot;:&quot;2022&#x2F;06&#x2F;02&#x2F;电商数仓（二）：业务数据采集平台&#x2F;&quot;,&quot;title&quot;:&quot;电商数仓（二）：业务数据采集平台&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>电商数仓（二）：业务数据采集平台 | Eitan's Blog</title><script src="/js/config.js"></script>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">
    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Eitan's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%B5%E5%95%86%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE"><span class="nav-number">1.</span> <span class="nav-text">电商业务数据</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E6%8B%9F%E7%94%9F%E6%88%90%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE"><span class="nav-number">1.1.</span> <span class="nav-text">模拟生成业务数据</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#MySQL%E5%AE%89%E8%A3%85"><span class="nav-number">1.1.1.</span> <span class="nav-text">MySQL安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90"><span class="nav-number">1.1.2.</span> <span class="nav-text">业务数据生成</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E9%80%9A%E8%BF%87%E8%84%9A%E6%9C%AC%E5%BB%BA%E8%A1%A8"><span class="nav-number">1.1.2.1.</span> <span class="nav-text">通过脚本建表</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE"><span class="nav-number">1.1.2.2.</span> <span class="nav-text">生成业务数据</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E4%BB%93%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="nav-number">2.</span> <span class="nav-text">数仓环境准备</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2"><span class="nav-number">2.1.</span> <span class="nav-text">Hive安装部署</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hive%E5%85%83%E6%95%B0%E6%8D%AE%E9%85%8D%E7%BD%AE%E5%88%B0MySQL"><span class="nav-number">2.2.</span> <span class="nav-text">Hive元数据配置到MySQL</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%AF%E5%8A%A8Hive"><span class="nav-number">2.3.</span> <span class="nav-text">启动Hive</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E5%85%83%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">2.3.1.</span> <span class="nav-text">初始化元数据库</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9%E5%85%83%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%97%E7%AC%A6%E9%9B%86"><span class="nav-number">2.3.2.</span> <span class="nav-text">修改元数据库字符集</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%96%E5%86%99hive%E5%90%AF%E5%8A%A8%E5%81%9C%E6%AD%A2%E8%84%9A%E6%9C%AC"><span class="nav-number">2.4.</span> <span class="nav-text">编写hive启动停止脚本</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E6%A8%A1%E5%9D%97"><span class="nav-number">3.</span> <span class="nav-text">业务数据采集模块</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%A6%82%E8%BF%B0"><span class="nav-number">3.1.</span> <span class="nav-text">业务数据同步概述</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E7%AD%96%E7%95%A5%E6%A6%82%E8%BF%B0"><span class="nav-number">3.1.1.</span> <span class="nav-text">数据同步策略概述</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E7%AD%96%E7%95%A5%E9%80%89%E6%8B%A9"><span class="nav-number">3.1.2.</span> <span class="nav-text">数据同步策略选择</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7%E6%A6%82%E8%BF%B0"><span class="nav-number">3.1.3.</span> <span class="nav-text">数据同步工具概述</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7%E9%83%A8%E7%BD%B2"><span class="nav-number">3.1.4.</span> <span class="nav-text">数据同步工具部署</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#DataX"><span class="nav-number">3.1.4.1.</span> <span class="nav-text">DataX</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Maxwell"><span class="nav-number">3.1.4.2.</span> <span class="nav-text">Maxwell</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%A8%E9%87%8F%E8%A1%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5"><span class="nav-number">3.2.</span> <span class="nav-text">全量表数据同步</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%80%9A%E9%81%93"><span class="nav-number">3.2.1.</span> <span class="nav-text">数据通道</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#DataX%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%94%9F%E6%88%90%E8%84%9A%E6%9C%AC"><span class="nav-number">3.2.2.</span> <span class="nav-text">DataX配置文件生成脚本</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E7%94%9F%E6%88%90%E7%9A%84DataX%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">3.2.3.</span> <span class="nav-text">测试生成的DataX配置文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%85%A8%E9%87%8F%E8%A1%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%84%9A%E6%9C%AC"><span class="nav-number">3.2.4.</span> <span class="nav-text">全量表数据同步脚本</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A2%9E%E9%87%8F%E8%A1%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5"><span class="nav-number">3.3.</span> <span class="nav-text">增量表数据同步</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%80%9A%E9%81%93-1"><span class="nav-number">3.3.1.</span> <span class="nav-text">数据通道</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Maxwell%E9%85%8D%E7%BD%AE"><span class="nav-number">3.3.2.</span> <span class="nav-text">Maxwell配置</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Flume%E9%85%8D%E7%BD%AE"><span class="nav-number">3.3.3.</span> <span class="nav-text">Flume配置</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Flume%E9%85%8D%E7%BD%AE%E6%A6%82%E8%BF%B0"><span class="nav-number">3.3.3.1.</span> <span class="nav-text">Flume配置概述</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Flume%E9%85%8D%E7%BD%AE%E5%AE%9E%E6%93%8D"><span class="nav-number">3.3.3.2.</span> <span class="nav-text">Flume配置实操</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%BC%96%E5%86%99Flume%E6%8B%A6%E6%88%AA"><span class="nav-number">3.3.3.3.</span> <span class="nav-text">编写Flume拦截</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%96%E5%86%99Flume%E5%90%AF%E5%81%9C%E8%84%9A%E6%9C%AC"><span class="nav-number">3.4.</span> <span class="nav-text">编写Flume启停脚本</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A2%9E%E9%87%8F%E8%A1%A8%E9%A6%96%E6%97%A5%E5%85%A8%E9%87%8F%E5%90%8C%E6%AD%A5"><span class="nav-number">3.4.1.</span> <span class="nav-text">增量表首日全量同步</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">4.</span> <span class="nav-text">总结</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86"><span class="nav-number">4.1.</span> <span class="nav-text">用户行为日志采集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86"><span class="nav-number">4.2.</span> <span class="nav-text">业务数据采集</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Eitan"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Eitan</p>
  <div class="site-description" itemprop="description">blog用于记忆，大脑擅长思考</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">47</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/eitan-blog" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;eitan-blog" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:eitan_blog@163.com" title="E-Mail → mailto:eitan_blog@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>




        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/yourname" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/06/02/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Eitan">
      <meta itemprop="description" content="blog用于记忆，大脑擅长思考">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Eitan's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          电商数仓（二）：业务数据采集平台
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-06-02 20:16:41" itemprop="dateCreated datePublished" datetime="2022-06-02T20:16:41+08:00">2022-06-02</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2022-06-06 16:31:08" itemprop="dateModified" datetime="2022-06-06T16:31:08+08:00">2022-06-06</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Big-Data/" itemprop="url" rel="index"><span itemprop="name">Big Data</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>20k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>18 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>本文为学习笔记，对应视频教程来自<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1nf4y1F7Bn">【尚硅谷】电商数仓V5.0</a></p>
<h3 id="电商业务数据"><a href="#电商业务数据" class="headerlink" title="电商业务数据"></a>电商业务数据</h3><h4 id="模拟生成业务数据"><a href="#模拟生成业务数据" class="headerlink" title="模拟生成业务数据"></a>模拟生成业务数据</h4><h5 id="MySQL安装"><a href="#MySQL安装" class="headerlink" title="MySQL安装"></a>MySQL安装</h5><p>参考<a target="_blank" rel="noopener" href="https://eitan-blog.github.io/2022/05/11/Hadoop%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AHive/">Hadoop（三）：Hive</a></p>
<h5 id="业务数据生成"><a href="#业务数据生成" class="headerlink" title="业务数据生成"></a>业务数据生成</h5><h6 id="通过脚本建表"><a href="#通过脚本建表" class="headerlink" title="通过脚本建表"></a>通过脚本建表</h6><h6 id="生成业务数据"><a href="#生成业务数据" class="headerlink" title="生成业务数据"></a>生成业务数据</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1.在hadoop102的/opt/module/目录下创建db_log文件夹</span></span><br><span class="line">[eitan@hadoop102 ~]$ mkdir /opt/module/db_log</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2.把gmall2020-mock-db-2021-11-14.jar和application.properties上传到hadoop102的/opt/module/db_log路径上</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3.根据需求修改application.properties相关配置</span></span><br><span class="line">[eitan@hadoop102 ~]$ vim /opt/module/db_log/application.properties</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4.在该目录下执行，如下命令，生成2020-06-14日期数据</span></span><br><span class="line">[eitan@hadoop102 db_log]$ java -jar gmall2020-mock-db-2021-11-14.jar </span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h3 id="数仓环境准备"><a href="#数仓环境准备" class="headerlink" title="数仓环境准备"></a>数仓环境准备</h3><h4 id="Hive安装部署"><a href="#Hive安装部署" class="headerlink" title="Hive安装部署"></a>Hive安装部署</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1.把apache-hive-3.1.2-bin.tar.gz上传到linux的/opt/software目录下并解压</span></span><br><span class="line">[eitan@hadoop102 ~]$ tar -zxf /opt/software/apache-hive-3.1.2-bin.tar.gz -C /opt/module/</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2.修改apache-hive-3.1.2-bin.tar.gz的名称为hive</span></span><br><span class="line">[eitan@hadoop102 ~]$ mv /opt/module/apache-hive-3.1.2-bin/ /opt/module/hive</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3.修改/etc/profile.d/my_env.sh，添加环境变量</span></span><br><span class="line">[eitan@hadoop102 ~]$ sudo vim /etc/profile.d/my_env.sh </span><br><span class="line"><span class="meta">#</span><span class="bash">HIVE_HOME</span></span><br><span class="line">export HIVE_HOME=/opt/module/hive</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure>

<h4 id="Hive元数据配置到MySQL"><a href="#Hive元数据配置到MySQL" class="headerlink" title="Hive元数据配置到MySQL"></a>Hive元数据配置到MySQL</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1.将MySQL的JDBC驱动拷贝到Hive的lib目录下</span></span><br><span class="line">[eitan@hadoop102 ~]$ mv /opt/software/mysql-connector-java-8.0.29.tar.gz /opt/module/hive/lib/</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2.配置MySQL作为元数据存储hive-site.xml</span></span><br><span class="line">[eitan@hadoop102 conf]$ vim hive-site.xml</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- 存储元数据mysql相关配置 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;jdbc:mysql://hadoop102:3306/hive?createDatabaseIfNotExist=true&amp;amp;useSSL=false&amp;amp;useUnicode=true&amp;amp;characterEncoding=UTF-8&lt;/value&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;jdbc:mysql://hadoop102:3306/hive?createDatabaseIfNotExist=true&amp;amp;useSSL=false&amp;amp;useUnicode=true&amp;amp;characterEncoding=UTF-8&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- Bind host on which to run the HiveServer2 Thrift interface --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hadoop102&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 远程模式部署metastore服务地址 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.metastore.uris&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;thrift://hadoop102:9083&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- 关闭元数据存储授权  --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.metastore.event.db.notification.api.auth&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 关闭元数据存储版本的验证 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.metastore.schema.verification&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 显示当前数据库，以及查询表的行头信息 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.cli.print.header&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.cli.print.current.db&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3.修改 hive-env.sh</span></span><br><span class="line">[eitan@hadoop102 conf]$ cp hive-env.sh.template hive-env.sh</span><br><span class="line">[eitan@hadoop102 conf]$ vim hive-env.sh</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="启动Hive"><a href="#启动Hive" class="headerlink" title="启动Hive"></a>启动Hive</h4><h5 id="初始化元数据库"><a href="#初始化元数据库" class="headerlink" title="初始化元数据库"></a>初始化元数据库</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[eitan@hadoop102 ~]$ /opt/module/hive/bin/schematool -initSchema -dbType mysql -verbose</span><br></pre></td></tr></table></figure>

<h5 id="修改元数据库字符集"><a href="#修改元数据库字符集" class="headerlink" title="修改元数据库字符集"></a>修改元数据库字符集</h5><p>Hive元数据库的字符集默认为Latin1，由于其不支持中文字符，故若建表语句中包含中文注释，会出现乱码现象。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 字段注释</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> COLUMNS_V2 MODIFY <span class="keyword">COLUMN</span> COMMENT <span class="type">VARCHAR</span> ( <span class="number">256</span> ) <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="comment">-- 表注释</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> TABLE_PARAMS MODIFY <span class="keyword">COLUMN</span> PARAM_VALUE MEDIUMTEXT <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br></pre></td></tr></table></figure>

<h4 id="编写hive启动停止脚本"><a href="#编写hive启动停止脚本" class="headerlink" title="编写hive启动停止脚本"></a>编写hive启动停止脚本</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[eitan@hadoop102 ~]$ vim bin/myhive.sh</span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;No Args Input...&quot;</span><br><span class="line">    exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)</span><br><span class="line">    echo &quot;================ 启动 Hive ================&quot;</span><br><span class="line">    echo &quot;---------------- 启动 metastore ----------------&quot;</span><br><span class="line">    ssh hadoop102 &quot;nohup /opt/module/hive/bin/hive --service metastore &gt; /home/eitan/log/metastore.out 2&gt;&amp;1 &amp;&quot;</span><br><span class="line">    echo &quot;---------------- 启动 hiveserver2 ----------------&quot;</span><br><span class="line">    ssh hadoop102 &quot;nohup /opt/module/hive/bin/hiveserver2 &gt; /home/eitan/log/hiveserver2.out 2&gt;&amp;1 &amp;&quot;</span><br><span class="line">;;</span><br><span class="line">&quot;stop&quot;)</span><br><span class="line">    echo &quot;================ 关闭 Hive ================&quot;</span><br><span class="line">    echo &quot;---------------- 关闭 metastore ----------------&quot;</span><br><span class="line">    ssh hadoop102 &quot;ps -ef | grep metastore | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9&quot;</span><br><span class="line">    echo &quot;---------------- 关闭 hiveserver2 ----------------&quot;</span><br><span class="line">    ssh hadoop102 &quot;ps -ef | grep hiveserver2 | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9&quot;</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">    echo &quot;Input Args Error...&quot;</span><br><span class="line">;;</span><br><span class="line">esac</span><br><span class="line"></span><br><span class="line">[eitan@hadoop102 ~]$ chmod u+x bin/myhive.sh</span><br></pre></td></tr></table></figure>

<h3 id="业务数据采集模块"><a href="#业务数据采集模块" class="headerlink" title="业务数据采集模块"></a>业务数据采集模块</h3><h4 id="业务数据同步概述"><a href="#业务数据同步概述" class="headerlink" title="业务数据同步概述"></a>业务数据同步概述</h4><h5 id="数据同步策略概述"><a href="#数据同步策略概述" class="headerlink" title="数据同步策略概述"></a>数据同步策略概述</h5><p>数据的同步策略有<strong>全量同步</strong>和<strong>增量同步</strong>。</p>
<p><strong>全量同步</strong>，就是每天都将业务数据库中的全部数据同步一份到数据仓库，这是保证两侧数据同步的最简单的方式。</p>
<p><strong>增量同步</strong>，就是每天只将业务数据中的新增及变化数据同步到数据仓库。采用每日增量同步的表，通常需要在首日先进行一次全量同步。</p>
<h5 id="数据同步策略选择"><a href="#数据同步策略选择" class="headerlink" title="数据同步策略选择"></a>数据同步策略选择</h5><table>
<thead>
<tr>
<th>同步策略</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>全量同步</td>
<td>逻辑简单</td>
<td>在某些情况下效率较低。例如某张表数据量较大，但是每天数据的变化比例很低，若对其采用每日全量同步，则会重复同步和存储大量相同的数据。</td>
</tr>
<tr>
<td>增量同步</td>
<td>效率高，无需同步和存储重复数据</td>
<td>逻辑复杂，需要将每日的新增及变化数据同原来的数据进行整合，才能使用</td>
</tr>
</tbody></table>
<p><img src="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220603122316.png" alt="image-20220603122312206"></p>
<h5 id="数据同步工具概述"><a href="#数据同步工具概述" class="headerlink" title="数据同步工具概述"></a>数据同步工具概述</h5><table>
<thead>
<tr>
<th>增量同步方案</th>
<th>DataX/Sqoop</th>
<th>Maxwell/Canal</th>
</tr>
</thead>
<tbody><tr>
<td>对数据库的要求</td>
<td>原理是基于查询，故若想通过select查询获取新增及变化数据，就要求数据表中存在create_time、update_time等字段，然后根据这些字段获取变更数据。</td>
<td>要求数据库记录变更操作，例如MySQL需开启binlog。</td>
</tr>
<tr>
<td>数据的中间状态</td>
<td>由于是离线批量同步，故若一条数据在一天中变化多次，该方案只能获取最后一个状态，中间状态无法获取。</td>
<td>由于是实时获取所有的数据变更操作，所以可以获取变更数据的所有中间状态。</td>
</tr>
</tbody></table>
<h5 id="数据同步工具部署"><a href="#数据同步工具部署" class="headerlink" title="数据同步工具部署"></a>数据同步工具部署</h5><h6 id="DataX"><a href="#DataX" class="headerlink" title="DataX"></a>DataX</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1.上传文件并解压</span></span><br><span class="line">[eitan@hadoop102 ~]$ tar -zxf /opt/software/datax.tar.gz -C /opt/module/</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2.测试运行</span></span><br><span class="line">[eitan@hadoop102 ~]$ python /opt/module/datax/bin/datax.py /opt/module/datax/job/job.json</span><br></pre></td></tr></table></figure>

<h6 id="Maxwell"><a href="#Maxwell" class="headerlink" title="Maxwell"></a>Maxwell</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1.上传文件并解压</span></span><br><span class="line">[eitan@hadoop102 ~]$ tar -zxf /opt/software/maxwell-1.29.2.tar.gz -C /opt/module/</span><br><span class="line">[eitan@hadoop102 ~]$ mv /opt/module/maxwell-1.29.2/ /opt/module/maxwell</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2.启用MySQL Binlog</span></span><br><span class="line">[eitan@hadoop102 ~]$ sudo vim /etc/my.cnf </span><br><span class="line">[mysqld]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 数据库id</span></span><br><span class="line">server-id = 1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动binlog，该参数的值会作为binlog的文件名</span></span><br><span class="line">log-bin=mysql-bin</span><br><span class="line"><span class="meta">#</span><span class="bash"> binlog类型，maxwell要求为row类型</span></span><br><span class="line">binlog_format=row</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启用binlog的数据库，需根据实际情况作出修改</span></span><br><span class="line">binlog-do-db=gmall</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 3.创建Maxwell所需数据库和用户</span></span><br><span class="line"><span class="comment">-- 创建数据库</span></span><br><span class="line"><span class="keyword">CREATE</span> DATABASE maxwell;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 调整MySQL数据库密码级别</span></span><br><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> validate_password_policy<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> validate_password_length<span class="operator">=</span><span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建Maxwell用户并赋予其必要权限</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">&#x27;maxwell&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;maxwell&#x27;</span>;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">ON</span> maxwell.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;maxwell&#x27;</span>@<span class="string">&#x27;%&#x27;</span>;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">SELECT</span>, REPLICATION CLIENT, REPLICATION SLAVE <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;maxwell&#x27;</span>@<span class="string">&#x27;%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 4.配置Maxwell</span></span><br><span class="line">[eitan@hadoop102 ~]$ cp /opt/module/maxwell/config.properties.example /opt/module/maxwell/config.properties</span><br><span class="line"></span><br><span class="line">[eitan@hadoop102 ~]$ vim /opt/module/maxwell/config.properties</span><br><span class="line">log_level=info</span><br><span class="line"></span><br><span class="line">producer=kafka</span><br><span class="line">kafka.bootstrap.servers=hadoop102:9092,hadoop103:9092,hadoop104:9092</span><br><span class="line">kafka_topic=maxwell</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> mysql login info</span></span><br><span class="line">host=hadoop102</span><br><span class="line">user=maxwell</span><br><span class="line">password=maxwell</span><br><span class="line">jdbc_options=useSSL=false&amp;serverTimezone=Asia/Shanghai</span><br></pre></td></tr></table></figure>

<h4 id="全量表数据同步"><a href="#全量表数据同步" class="headerlink" title="全量表数据同步"></a>全量表数据同步</h4><h5 id="数据通道"><a href="#数据通道" class="headerlink" title="数据通道"></a>数据通道</h5><p>全量表数据由DataX从MySQL业务数据库直接同步到HDFS，具体数据流向如下图所示。</p>
<p><img src="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220604151701.png" alt="image-20220604151658669"></p>
<h5 id="DataX配置文件生成脚本"><a href="#DataX配置文件生成脚本" class="headerlink" title="DataX配置文件生成脚本"></a>DataX配置文件生成脚本</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[eitan@hadoop102 ~]$ vim ./bin/gen_import_config.py</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> getopt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> MySQLdb</span><br><span class="line"></span><br><span class="line"><span class="comment">#MySQL相关配置，需根据实际情况作出修改</span></span><br><span class="line">mysql_host = <span class="string">&quot;hadoop102&quot;</span></span><br><span class="line">mysql_port = <span class="string">&quot;3306&quot;</span></span><br><span class="line">mysql_user = <span class="string">&quot;root&quot;</span></span><br><span class="line">mysql_passwd = <span class="string">&quot;root&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#HDFS NameNode相关配置，需根据实际情况作出修改</span></span><br><span class="line">hdfs_nn_host = <span class="string">&quot;hadoop102&quot;</span></span><br><span class="line">hdfs_nn_port = <span class="string">&quot;8020&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#生成配置文件的目标路径，可根据实际情况作出修改</span></span><br><span class="line">output_path = <span class="string">&quot;/opt/module/datax/job/import&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取mysql连接</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_connection</span>():</span></span><br><span class="line">    <span class="keyword">return</span> MySQLdb.connect(host=mysql_host, port=<span class="built_in">int</span>(mysql_port), user=mysql_user, passwd=mysql_passwd)</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取表格的元数据  包含列名和数据类型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_mysql_meta</span>(<span class="params">database, table</span>):</span></span><br><span class="line">    connection = get_connection()</span><br><span class="line">    cursor = connection.cursor()</span><br><span class="line">    sql = <span class="string">&quot;SELECT COLUMN_NAME,DATA_TYPE from information_schema.COLUMNS WHERE TABLE_SCHEMA=%s AND TABLE_NAME=%s ORDER BY ORDINAL_POSITION&quot;</span></span><br><span class="line">    cursor.execute(sql, [database, table])</span><br><span class="line">    fetchall = cursor.fetchall()</span><br><span class="line">    cursor.close()</span><br><span class="line">    connection.close()</span><br><span class="line">    <span class="keyword">return</span> fetchall</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取mysql表的列名</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_mysql_columns</span>(<span class="params">database, table</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">map</span>(<span class="keyword">lambda</span> x: x[<span class="number">0</span>], get_mysql_meta(database, table))</span><br><span class="line"></span><br><span class="line"><span class="comment">#将获取的元数据中mysql的数据类型转换为hive的数据类型  写入到hdfswriter中</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_hive_columns</span>(<span class="params">database, table</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">type_mapping</span>(<span class="params">mysql_type</span>):</span></span><br><span class="line">        mappings = &#123;</span><br><span class="line">            <span class="string">&quot;bigint&quot;</span>: <span class="string">&quot;bigint&quot;</span>,</span><br><span class="line">            <span class="string">&quot;int&quot;</span>: <span class="string">&quot;bigint&quot;</span>,</span><br><span class="line">            <span class="string">&quot;smallint&quot;</span>: <span class="string">&quot;bigint&quot;</span>,</span><br><span class="line">            <span class="string">&quot;tinyint&quot;</span>: <span class="string">&quot;bigint&quot;</span>,</span><br><span class="line">            <span class="string">&quot;decimal&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">            <span class="string">&quot;double&quot;</span>: <span class="string">&quot;double&quot;</span>,</span><br><span class="line">            <span class="string">&quot;float&quot;</span>: <span class="string">&quot;float&quot;</span>,</span><br><span class="line">            <span class="string">&quot;binary&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">            <span class="string">&quot;char&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">            <span class="string">&quot;varchar&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">            <span class="string">&quot;datetime&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">            <span class="string">&quot;time&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">            <span class="string">&quot;timestamp&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">            <span class="string">&quot;date&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">            <span class="string">&quot;text&quot;</span>: <span class="string">&quot;string&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> mappings[mysql_type]</span><br><span class="line"></span><br><span class="line">    meta = get_mysql_meta(database, table)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">map</span>(<span class="keyword">lambda</span> x: &#123;<span class="string">&quot;name&quot;</span>: x[<span class="number">0</span>], <span class="string">&quot;type&quot;</span>: type_mapping(x[<span class="number">1</span>].lower())&#125;, meta)</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成json文件</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_json</span>(<span class="params">source_database, source_table</span>):</span></span><br><span class="line">    job = &#123;</span><br><span class="line">        <span class="string">&quot;job&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;setting&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;speed&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;channel&quot;</span>: <span class="number">3</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="string">&quot;errorLimit&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;record&quot;</span>: <span class="number">0</span>,</span><br><span class="line">                    <span class="string">&quot;percentage&quot;</span>: <span class="number">0.02</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;content&quot;</span>: [&#123;</span><br><span class="line">                <span class="string">&quot;reader&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;mysqlreader&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;username&quot;</span>: mysql_user,</span><br><span class="line">                        <span class="string">&quot;password&quot;</span>: mysql_passwd,</span><br><span class="line">                        <span class="string">&quot;column&quot;</span>: get_mysql_columns(source_database, source_table),</span><br><span class="line">                        <span class="string">&quot;splitPk&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;connection&quot;</span>: [&#123;</span><br><span class="line">                            <span class="string">&quot;table&quot;</span>: [source_table],</span><br><span class="line">                            <span class="string">&quot;jdbcUrl&quot;</span>: [<span class="string">&quot;jdbc:mysql://&quot;</span> + mysql_host + <span class="string">&quot;:&quot;</span> + mysql_port + <span class="string">&quot;/&quot;</span> + source_database]</span><br><span class="line">                        &#125;]</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="string">&quot;writer&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;hdfswriter&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;defaultFS&quot;</span>: <span class="string">&quot;hdfs://&quot;</span> + hdfs_nn_host + <span class="string">&quot;:&quot;</span> + hdfs_nn_port,</span><br><span class="line">                        <span class="string">&quot;fileType&quot;</span>: <span class="string">&quot;text&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;path&quot;</span>: <span class="string">&quot;$&#123;targetdir&#125;&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;fileName&quot;</span>: source_table,</span><br><span class="line">                        <span class="string">&quot;column&quot;</span>: get_hive_columns(source_database, source_table),</span><br><span class="line">                        <span class="string">&quot;writeMode&quot;</span>: <span class="string">&quot;append&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;fieldDelimiter&quot;</span>: <span class="string">&quot;\t&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;compress&quot;</span>: <span class="string">&quot;gzip&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_path):</span><br><span class="line">        os.makedirs(output_path)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(output_path, <span class="string">&quot;.&quot;</span>.join([source_database, source_table, <span class="string">&quot;json&quot;</span>])), <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        json.dump(job, f)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">args</span>):</span></span><br><span class="line">    source_database = <span class="string">&quot;&quot;</span></span><br><span class="line">    source_table = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    options, arguments = getopt.getopt(args, <span class="string">&#x27;-d:-t:&#x27;</span>, [<span class="string">&#x27;sourcedb=&#x27;</span>, <span class="string">&#x27;sourcetbl=&#x27;</span>])</span><br><span class="line">    <span class="keyword">for</span> opt_name, opt_value <span class="keyword">in</span> options:</span><br><span class="line">        <span class="keyword">if</span> opt_name <span class="keyword">in</span> (<span class="string">&#x27;-d&#x27;</span>, <span class="string">&#x27;--sourcedb&#x27;</span>):</span><br><span class="line">            source_database = opt_value</span><br><span class="line">        <span class="keyword">if</span> opt_name <span class="keyword">in</span> (<span class="string">&#x27;-t&#x27;</span>, <span class="string">&#x27;--sourcetbl&#x27;</span>):</span><br><span class="line">            source_table = opt_value</span><br><span class="line"></span><br><span class="line">    generate_json(source_database, source_table)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main(sys.argv[<span class="number">1</span>:])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装Python Mysql驱动</span></span><br><span class="line">[eitan@hadoop102 ~]$ sudo yum install -y MySQL-python</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 脚本使用说明</span></span><br><span class="line">[eitan@hadoop102 ~]$ python ~/bin/gen_import_config.py -d gmall -t activity_info</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在~/bin目录下创建gen_import_config.sh脚本</span></span><br><span class="line">[eitan@hadoop102 ~]$ vim ~/bin/gen_import_config.sh</span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">python ~/bin/gen_import_config.py -d gmall -t activity_info</span><br><span class="line">python ~/bin/gen_import_config.py -d gmall -t activity_rule</span><br><span class="line">python ~/bin/gen_import_config.py -d gmall -t base_category1</span><br><span class="line">python ~/bin/gen_import_config.py -d gmall -t base_category2</span><br><span class="line">python ~/bin/gen_import_config.py -d gmall -t base_category3</span><br><span class="line">python ~/bin/gen_import_config.py -d gmall -t base_dic</span><br><span class="line">python ~/bin/gen_import_config.py -d gmall -t base_province</span><br><span class="line">python ~/bin/gen_import_config.py -d gmall -t base_region</span><br><span class="line">python ~/bin/gen_import_config.py -d gmall -t base_trademark</span><br><span class="line">python ~/bin/gen_import_config.py -d gmall -t cart_info</span><br><span class="line">python ~/bin/gen_import_config.py -d gmall -t coupon_info</span><br><span class="line">python ~/bin/gen_import_config.py -d gmall -t sku_attr_value</span><br><span class="line">python ~/bin/gen_import_config.py -d gmall -t sku_info</span><br><span class="line">python ~/bin/gen_import_config.py -d gmall -t sku_sale_attr_value</span><br><span class="line">python ~/bin/gen_import_config.py -d gmall -t spu_info</span><br><span class="line"></span><br><span class="line">[eitan@hadoop102 ~]$ chmod u+x ~/bin/gen_import_config.sh</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 执行gen_import_config.sh脚本</span></span><br><span class="line">[eitan@hadoop102 ~]$ ./bin/gen_import_config.sh </span><br></pre></td></tr></table></figure>

<h5 id="测试生成的DataX配置文件"><a href="#测试生成的DataX配置文件" class="headerlink" title="测试生成的DataX配置文件"></a>测试生成的DataX配置文件</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1.创建目标路径</span></span><br><span class="line">[eitan@hadoop102 ~]$ hadoop fs -mkdir -p /origin_data/gmall/db/activity_info_full/2020-06-14</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2.执行DataX同步命令</span></span><br><span class="line">[eitan@hadoop102 ~]$ python /opt/module/datax/bin/datax.py -p &quot;-Dtargetdir=/origin_data/gmall/db/activity_info_full/2020-06-14&quot; /opt/module/datax/job/import/gmall.activity_info.json</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3.查看hdfs数据</span></span><br><span class="line">[eitan@hadoop102 ~]$ hadoop fs -cat /origin_data/gmall/db/activity_info_full/2020-06-14/* | zcat</span><br><span class="line">2022-06-04 20:25:41,798 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br><span class="line">1	联想专场	3101	联想满减	2020-10-21 18:49:12	2020-10-31 18:49:15	</span><br><span class="line">2	Apple品牌日	3101	Apple品牌日	2020-06-10 00:00:00	2020-06-12 00:00:00	</span><br><span class="line">3	女神节	3102	满件打折	2020-03-08 00:00:00	2020-03-09 00:00:00	</span><br></pre></td></tr></table></figure>

<h5 id="全量表数据同步脚本"><a href="#全量表数据同步脚本" class="headerlink" title="全量表数据同步脚本"></a>全量表数据同步脚本</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[eitan@hadoop102 ~]$ vim ~/bin/mysql_to_hdfs_full.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[eitan@hadoop102 ~]$ chmod u+x ~/bin/mysql_to_hdfs_full.sh</span><br></pre></td></tr></table></figure>

<h4 id="增量表数据同步"><a href="#增量表数据同步" class="headerlink" title="增量表数据同步"></a>增量表数据同步</h4><h5 id="数据通道-1"><a href="#数据通道-1" class="headerlink" title="数据通道"></a>数据通道</h5><p><img src="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220605145305.png" alt="image-20220605145301020"></p>
<h5 id="Maxwell配置"><a href="#Maxwell配置" class="headerlink" title="Maxwell配置"></a>Maxwell配置</h5><p>按照规划，有cart_info、comment_info等共计13张表需进行增量同步，默认情况下，Maxwell会同步binlog中的所有表的数据变更记录，因此我们需要对Maxwell进行配置，另其只同步这特定的13张表。</p>
<p>另外，为方便下游使用数据，还需对Maxwell进行配置，另其将不同表的数据发往不同的Kafka Topic。Maxwell最终配置如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[eitan@hadoop102 ~]$ vim /opt/module/maxwell/config.properties</span><br><span class="line">log_level=info</span><br><span class="line"></span><br><span class="line">producer=kafka</span><br><span class="line">kafka.bootstrap.servers=hadoop102:9092,hadoop103:9092,hadoop104:9092</span><br><span class="line">kafka_topic=%&#123;table&#125;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> mysql login info</span></span><br><span class="line">host=hadoop102</span><br><span class="line">user=maxwell</span><br><span class="line">password=maxwell</span><br><span class="line">jdbc_options=useSSL=false&amp;serverTimezone=Asia/Shanghai</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">表过滤，只同步特定的13张表</span></span><br><span class="line">filter= include:gmall.cart_info,include:gmall.comment_info,include:gmall.coupon_use,include:gmall.favor_info,include:gmall.order_detail,include:gmall.order_detail_activity,include:gmall.order_detail_coupon,include:gmall.order_info,include:gmall.order_refund_info,include:gmall.order_status_log,include:gmall.payment_info,include:gmall.refund_payment,include:gmall.user_info</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动kafka查看是否可用接收消息</span></span><br><span class="line">[eitan@hadoop102 ~]$ zk.sh start</span><br><span class="line">[eitan@hadoop102 ~]$ kf.sh start</span><br><span class="line">[eitan@hadoop102 ~]$ mxw.sh restart</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动一个Kafka Console Consumer，消费任一topic数据</span></span><br><span class="line">[eitan@hadoop102 ~]$ /opt/module/kafka/bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic cart_info</span><br></pre></td></tr></table></figure>

<h5 id="Flume配置"><a href="#Flume配置" class="headerlink" title="Flume配置"></a>Flume配置</h5><h6 id="Flume配置概述"><a href="#Flume配置概述" class="headerlink" title="Flume配置概述"></a>Flume配置概述</h6><p>Flume需要将Kafka中各topic的数据传输到HDFS，故其需选用KafkaSource以及HDFSSink，Channe选用FileChanne。</p>
<p>需要注意的是，KafkaSource需订阅Kafka中的13个topic，HDFSSink需要将不同topic的数据写到不同的路径，并且路径中应当包含一层日期，用于区分每天的数据。关键配置如下：</p>
<p><img src="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220605153029.png" alt="image-20220605153027849"></p>
<h6 id="Flume配置实操"><a href="#Flume配置实操" class="headerlink" title="Flume配置实操"></a>Flume配置实操</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">[eitan@hadoop102 ~]$ cp /opt/module/flume/job/kafka_to_hdfs.conf /opt/module/flume/job/kafka_to_hdfs_db.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 组件</span></span></span><br><span class="line">a1.sources=r1</span><br><span class="line">a1.channels=c1</span><br><span class="line">a1.sinks=k1</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource</span><br><span class="line">a1.sources.r1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092</span><br><span class="line">a1.sources.r1.kafka.consumer.group.id = flume</span><br><span class="line">a1.sources.r1.kafka.topics = cart_info,comment_info,coupon_use,favor_info,order_detail_activity,order_detail_coupon,order_detail,order_info,order_refund_info,order_status_log,payment_info,refund_payment,user_info</span><br><span class="line"></span><br><span class="line">a1.sources.r1.setTopicHeader = true</span><br><span class="line">a1.sources.r1.topicHeader = topic</span><br><span class="line"></span><br><span class="line">a1.sources.r1.batchSize = 5000</span><br><span class="line">a1.sources.r1.batchDurationMillis = 2000</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Interceptor</span></span><br><span class="line">a1.sources.r1.interceptors = i1</span><br><span class="line">a1.sources.r1.interceptors.i1.type = com.atguigu.flume.interceptor.db.TimestampInterceptor$Builder</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> channel</span></span><br><span class="line">a1.channels.c1.type = file</span><br><span class="line">a1.channels.c1.checkpointDir = /opt/module/flume/checkpoint/behavior2</span><br><span class="line">a1.channels.c1.dataDirs = /opt/module/flume/data/behavior2/</span><br><span class="line"></span><br><span class="line">a1.channels.c1.maxFileSize = 2146435071</span><br><span class="line">a1.channels.c1.capacity = 1000000</span><br><span class="line">a1.channels.c1.keep-alive = 6</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sink1</span></span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path = /origin_data/gmall/db/%&#123;topic&#125;_inc/%Y-%m-%d</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = db-</span><br><span class="line">a1.sinks.k1.hdfs.round = false</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.hdfs.rollInterval = 10</span><br><span class="line">a1.sinks.k1.hdfs.rollSize = 134217728</span><br><span class="line">a1.sinks.k1.hdfs.rollCount = 0</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 控制输出文件是原生文件</span></span><br><span class="line">a1.sinks.k1.hdfs.fileType = CompressedStream</span><br><span class="line">a1.sinks.k1.hdfs.codeC = gzip</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 拼装</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel= c1</span><br></pre></td></tr></table></figure>

<h6 id="编写Flume拦截"><a href="#编写Flume拦截" class="headerlink" title="编写Flume拦截"></a>编写Flume拦截</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.flume.interceptor.db;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Context;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Event;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.interceptor.Interceptor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimestampInterceptor</span> <span class="keyword">implements</span> <span class="title">Interceptor</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Event <span class="title">intercept</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">        Map&lt;String, String&gt; headers = event.getHeaders();</span><br><span class="line">        JSONObject jsonObject = JSONObject.parseObject(<span class="keyword">new</span> String(event.getBody()));</span><br><span class="line"></span><br><span class="line">        Long ts = jsonObject.getLong(<span class="string">&quot;ts&quot;</span>);</span><br><span class="line">        headers.put(<span class="string">&quot;timestamp&quot;</span>, String.valueOf(ts * <span class="number">1000</span>));</span><br><span class="line">        <span class="keyword">return</span> event;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Event&gt; <span class="title">intercept</span><span class="params">(List&lt;Event&gt; list)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (Event event : list) &#123;</span><br><span class="line">            intercept(event);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> list;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Builder</span> <span class="keyword">implements</span> <span class="title">Interceptor</span>.<span class="title">Builder</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Interceptor <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> TimestampInterceptor();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上传jar包</p>
<p><img src="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220605180311.png" alt="image-20220605180309350"></p>
<h4 id="编写Flume启停脚本"><a href="#编写Flume启停脚本" class="headerlink" title="编写Flume启停脚本"></a>编写Flume启停脚本</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[eitan@hadoop102 ~]$ vim ./bin/f3.sh</span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">case $1 in</span><br><span class="line">    &quot;start&quot;)</span><br><span class="line">    echo &quot;-------- 启动 hadoop104 业务数据服务 flume --------&quot;</span><br><span class="line">    ssh hadoop104 &quot;nohup /opt/module/flume/bin/flume-ng agent -n a1 -c /opt/module/flume/conf -f /opt/module/flume/job/kafka_to_hdfs_db.conf &gt;/dev/null 2&gt;&amp;1 &amp;&quot;</span><br><span class="line">    ;;</span><br><span class="line">    &quot;stop&quot;)</span><br><span class="line">    echo &quot;-------- 停止 hadoop104 业务数据服务 flume --------&quot;</span><br><span class="line">    ssh hadoop104 &quot;ps -ef | grep kafka_to_hdfs_db.conf | grep -v grep | awk &#x27;&#123;print \$2&#125;&#x27; | xargs -n1 kill&quot;</span><br><span class="line">    ;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>



<h5 id="增量表首日全量同步"><a href="#增量表首日全量同步" class="headerlink" title="增量表首日全量同步"></a>增量表首日全量同步</h5><p>通常情况下，增量表需要在首日进行一次全量同步，后续每日再进行增量同步，首日全量同步可以使用Maxwell的bootstrap功能。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">[eitan@hadoop102 ~]$ vim ~/bin/mysql_to_kafka_inc_init.sh</span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 该脚本作用是初始化所有增量表，只需执行一次</span></span><br><span class="line"></span><br><span class="line">MAXWELL_HOME=/opt/module/maxwell</span><br><span class="line"></span><br><span class="line">import_data()&#123;</span><br><span class="line"><span class="meta"> $</span><span class="bash">MAXWELL_HOME/bin/maxwell-bootstrap --database gmall --table <span class="variable">$1</span> --config <span class="variable">$MAXWELL_HOME</span>/config.properties</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">&quot;cart_info&quot;)</span><br><span class="line">  import_data cart_info</span><br><span class="line">  ;;</span><br><span class="line">&quot;comment_info&quot;)</span><br><span class="line">  import_data comment_info</span><br><span class="line">  ;;</span><br><span class="line">&quot;coupon_use&quot;)</span><br><span class="line">  import_data coupon_use</span><br><span class="line">  ;;</span><br><span class="line">&quot;favor_info&quot;)</span><br><span class="line">  import_data favor_info</span><br><span class="line">  ;;</span><br><span class="line">&quot;order_detail&quot;)</span><br><span class="line">  import_data order_detail</span><br><span class="line">  ;;</span><br><span class="line">&quot;order_detail_activity&quot;)</span><br><span class="line">  import_data order_detail_activity</span><br><span class="line">  ;;</span><br><span class="line">&quot;order_detail_coupon&quot;)</span><br><span class="line">  import_data order_detail_coupon</span><br><span class="line">  ;;</span><br><span class="line">&quot;order_info&quot;)</span><br><span class="line">  import_data order_info</span><br><span class="line">  ;;</span><br><span class="line">&quot;order_refund_info&quot;)</span><br><span class="line">  import_data order_refund_info</span><br><span class="line">  ;;</span><br><span class="line">&quot;order_status_log&quot;)</span><br><span class="line">  import_data order_status_log</span><br><span class="line">  ;;</span><br><span class="line">&quot;payment_info&quot;)</span><br><span class="line">  import_data payment_info</span><br><span class="line">  ;;</span><br><span class="line">&quot;refund_payment&quot;)</span><br><span class="line">  import_data refund_payment</span><br><span class="line">  ;;</span><br><span class="line">&quot;user_info&quot;)</span><br><span class="line">  import_data user_info</span><br><span class="line">  ;;</span><br><span class="line">&quot;all&quot;)</span><br><span class="line">  import_data cart_info</span><br><span class="line">  import_data comment_info</span><br><span class="line">  import_data coupon_use</span><br><span class="line">  import_data favor_info</span><br><span class="line">  import_data order_detail</span><br><span class="line">  import_data order_detail_activity</span><br><span class="line">  import_data order_detail_coupon</span><br><span class="line">  import_data order_info</span><br><span class="line">  import_data order_refund_info</span><br><span class="line">  import_data order_status_log</span><br><span class="line">  import_data payment_info</span><br><span class="line">  import_data refund_payment</span><br><span class="line">  import_data user_info</span><br><span class="line">  ;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><h4 id="用户行为日志采集"><a href="#用户行为日志采集" class="headerlink" title="用户行为日志采集"></a>用户行为日志采集</h4><p><img src="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220606110929.png" alt="flowchart1"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1.基础环境 hadoop集群、zookeeper集群</span></span><br><span class="line">[eitan@hadoop102 ~]$ jpsall </span><br><span class="line">--------- hadoop102 ----------</span><br><span class="line">11056 JobHistoryServer</span><br><span class="line">10886 NodeManager</span><br><span class="line">11146 QuorumPeerMain</span><br><span class="line">10602 DataNode</span><br><span class="line">10459 NameNode</span><br><span class="line">--------- hadoop103 ----------</span><br><span class="line">10752 QuorumPeerMain</span><br><span class="line">10256 ResourceManager</span><br><span class="line">10391 NodeManager</span><br><span class="line">10079 DataNode</span><br><span class="line">--------- hadoop104 ----------</span><br><span class="line">7971 QuorumPeerMain</span><br><span class="line">7827 NodeManager</span><br><span class="line">7741 SecondaryNameNode</span><br><span class="line">7630 DataNode</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2.启动服务</span></span><br><span class="line">[eitan@hadoop102 ~]$ kf.sh start</span><br><span class="line">[eitan@hadoop102 ~]$ f1.sh start</span><br><span class="line">[eitan@hadoop102 ~]$ f2.sh start</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3.模拟生成日志数据</span></span><br><span class="line">[eitan@hadoop102 ~]$ lg.sh</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4.生成 2020-06-15 的日志数据</span></span><br><span class="line">[eitan@hadoop102 ~]$ vim /opt/module/applog/application.yml</span><br><span class="line"><span class="meta">#</span><span class="bash">业务日期</span></span><br><span class="line">mock.date: &quot;2020-06-15&quot;</span><br><span class="line"></span><br><span class="line">[eitan@hadoop102 ~]$ xsync /opt/module/applog/application.yml</span><br><span class="line">[eitan@hadoop102 ~]$ lg.sh</span><br></pre></td></tr></table></figure>

<h4 id="业务数据采集"><a href="#业务数据采集" class="headerlink" title="业务数据采集"></a>业务数据采集</h4><p><img src="https://raw.githubusercontent.com/xyq-material/image/master/blog/20220606163057.png" alt="flowchart2"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1.生成DATAX对应脚本</span></span><br><span class="line">[eitan@hadoop102 ~]$ gen_import_config.sh </span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2.生成初始数据</span></span><br><span class="line">[eitan@hadoop102 ~]$ vim /opt/module/db_log/application.properties </span><br><span class="line"><span class="meta">#</span><span class="bash">业务日期</span></span><br><span class="line">mock.date=2020-06-14</span><br><span class="line"><span class="meta">#</span><span class="bash">是否重置，首日须置为1，之后置为0</span></span><br><span class="line">mock.clear=1</span><br><span class="line"><span class="meta">#</span><span class="bash">是否重置用户，首日须置为1，之后置为0</span></span><br><span class="line">mock.clear.user=1</span><br><span class="line"></span><br><span class="line">[eitan@hadoop102 ~]$ cd /opt/module/db_log/</span><br><span class="line">[eitan@hadoop102 db_log]$ java -jar gmall2020-mock-db-2021-11-14.jar</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3.使用DATAX同步数据</span></span><br><span class="line">[eitan@hadoop102 ~]$ mysql_to_hdfs_full.sh all 2020-06-14</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1.启动maxwell和flume</span></span><br><span class="line">[eitan@hadoop102 ~]$ mxw.sh start</span><br><span class="line">[eitan@hadoop102 ~]$ f3.sh start</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2.使用maxwell-bootstrap功能进行首日全量同步</span></span><br><span class="line">[eitan@hadoop102 ~]$ mysql_to_kafka_inc_init.sh all</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1.修改maxwell的配置文件</span></span><br><span class="line">[eitan@hadoop102 ~]$ vim /opt/module/maxwell/config.properties</span><br><span class="line"><span class="meta">#</span><span class="bash"> 教学版专用配置，和/opt/module/db_log/application.properties中的mock.date参数保持一致</span></span><br><span class="line">mock_date=2020-06-15</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2.重启maxwell</span></span><br><span class="line">[eitan@hadoop102 ~]$ mxw.sh restart</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3.修改application.properties文件，修改为相同日期</span></span><br><span class="line">[eitan@hadoop102 ~]$ vim /opt/module/db_log/application.properties </span><br><span class="line"><span class="meta">#</span><span class="bash">业务日期</span></span><br><span class="line">mock.date=2020-06-15</span><br><span class="line"><span class="meta">#</span><span class="bash">是否重置，首日须置为1，之后置为0</span></span><br><span class="line">mock.clear=0</span><br><span class="line"><span class="meta">#</span><span class="bash">是否重置用户，首日须置为1，之后置为0</span></span><br><span class="line">mock.clear.user=0</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4.启动程序生成数据</span></span><br><span class="line">[eitan@hadoop102 ~]$ cd /opt/module/db_log/</span><br><span class="line">[eitan@hadoop102 db_log]$ java -jar gmall2020-mock-db-2021-11-14.jar</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>Eitan
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="http://example.com/2022/06/02/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B0/" title="电商数仓（二）：业务数据采集平台">http://example.com/2022/06/02/电商数仓（二）：业务数据采集平台/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/Project/" rel="tag"><i class="fa fa-tag"></i> Project</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/05/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B0/" rel="prev" title="电商数仓（一）：用户行为采集平台">
                  <i class="fa fa-chevron-left"></i> 电商数仓（一）：用户行为采集平台
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/06/06/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E7%94%B5%E5%95%86%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E8%AE%BE%E8%AE%A1/" rel="next" title="电商数仓（三）：电商数据仓库设计">
                  电商数仓（三）：电商数据仓库设计 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>





<script src="/js/comments.js"></script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Eitan</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="/js/third-party/search/local-search.js"></script>






  





</body>
</html>
